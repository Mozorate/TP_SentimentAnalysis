{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut0yHLRTnxGT"
      },
      "source": [
        "# Imports nécessaires à l'ensemble du projet de TLN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAddi-00SD9m",
        "outputId": "c07521c8-ed36-4f29-d6d8-e25a3c03b091"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to\n",
            "[nltk_data]     C:\\Users\\Alexis\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Alexis\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Alexis\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as et \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import en_core_web_sm\n",
        "import nltk\n",
        "from nltk import ne_chunk, pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40fp3Xuph3m"
      },
      "source": [
        "# TP ANALYSE DE SENTIMENT  RESTAURANTS\n",
        "Le jeu de données Restaurant_Train est composé de 3041 phrases en anglais tirées des critiques de restaurants. Les valeurs possibles pour la polarité des aspects sont : “positive”, “negative”, “conflict”, “neutral”. Les valeurs possibles des categories sont : “food”, “service”, “price”, “ambience”, “anecdotes/miscellaneous”.\n",
        "\n",
        "Dans cette partie nous allons effectuer différents traitements :\n",
        "* Création des dataframes (TRAIN et TEST GOLD)\n",
        "* Tokenize et Pos Tags\n",
        "* Partie sentiments\n",
        "  * Assignation de la polarité de chaque mot \n",
        "  * Ajout des polarités dans les dataframes\n",
        "  * Tri dans les dataframes\n",
        "* Visualisation\n",
        "  * Repartition de la polarite\n",
        "  * Conversion des dataframes en listes\n",
        "* Vectorisation — TF/IDF\n",
        "  * Fréquence de terme/Fréquence de document inverse (TF/IDF)\n",
        "  * Premier test avec seulement la colonne text comme variable explicative\n",
        "  * Normalisation des dimensions de nos listes.\n",
        "  * Vectorisation avec TfidfTransformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xue-enzrnvl4"
      },
      "source": [
        "## Création des dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rlxSeQkUkU75",
        "outputId": "c4a00514-3da1-4540-c288-ad96ea972564"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>57</td>\n",
              "      <td>61</td>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kitchen</td>\n",
              "      <td>positive</td>\n",
              "      <td>55</td>\n",
              "      <td>62</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>menu</td>\n",
              "      <td>neutral</td>\n",
              "      <td>141</td>\n",
              "      <td>145</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      term  polarity from   to    id  \\\n",
              "0    staff  negative    8   13  3121   \n",
              "1     food  positive   57   61  2777   \n",
              "2     food  positive    4    8  1634   \n",
              "3  kitchen  positive   55   62  1634   \n",
              "4     menu   neutral  141  145  1634   \n",
              "\n",
              "                                                text  \n",
              "0               But the staff was so horrible to us.  \n",
              "1  To be completely fair, the only redeeming fact...  \n",
              "2  The food is uniformly exceptional, with a very...  \n",
              "3  The food is uniformly exceptional, with a very...  \n",
              "4  The food is uniformly exceptional, with a very...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  CREATE TRAIN DATAFRAME \n",
        "l = []\n",
        "\n",
        "xtree = et.parse(\"Restaurants_Train.xml\")\n",
        "xroot = xtree.getroot()\n",
        "for sentence in xroot.findall('sentence'):\n",
        "    idi = sentence.get('id')\n",
        "    text = sentence.find('text').text\n",
        "\n",
        "    for neighbor in sentence.iter('aspectTerm'):\n",
        "        # On mets 'id' et 'text' dans le dictionnaire avec toutes les variable qui nous intéresse\n",
        "        neighbor.attrib['id'] = idi\n",
        "        neighbor.attrib['text'] = text\n",
        "        # on stock tous les dictionnaires crées dans une liste\n",
        "        l.append(neighbor.attrib)\n",
        "        \n",
        "df_train = pd.DataFrame(l)\n",
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j5GYEmgJko1q",
        "outputId": "fbec0878-df57-4e63-852c-4fa70bb9785e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pasta</td>\n",
              "      <td>positive</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>portions</td>\n",
              "      <td>positive</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>1579</td>\n",
              "      <td>And really large portions.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term  polarity from  to    id  \\\n",
              "0  appetizers  positive    8  18   813   \n",
              "1      salads  positive   23  29   813   \n",
              "2       steak  positive   49  54   813   \n",
              "3       pasta  positive   82  87   813   \n",
              "4    portions  positive   17  25  1579   \n",
              "\n",
              "                                                text  \n",
              "0  All the appetizers and salads were fabulous, t...  \n",
              "1  All the appetizers and salads were fabulous, t...  \n",
              "2  All the appetizers and salads were fabulous, t...  \n",
              "3  All the appetizers and salads were fabulous, t...  \n",
              "4                         And really large portions.  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  CREATE Test GOLD DATAFRAME \n",
        "l = []\n",
        "\n",
        "xtreeGoldTest = et.parse(\"Restaurants_Test_Gold.xml\")\n",
        "xroot = xtreeGoldTest.getroot()\n",
        "for sentence in xroot.findall('sentence'):\n",
        "    idi = sentence.get('id')\n",
        "    text = sentence.find('text').text\n",
        "    \n",
        "    #print(idi, text)\n",
        "    for neighbor in sentence.iter('aspectTerm'):\n",
        "        # On mets 'id' et 'text' dans le dictionnaire avec toutes les variable qui nous intéresse\n",
        "        neighbor.attrib['id'] = idi\n",
        "        neighbor.attrib['text'] = text\n",
        "        # on stock tous les dictionnaires crées dans une liste\n",
        "        l.append(neighbor.attrib)\n",
        "df_testGold = pd.DataFrame(l)\n",
        "df_testGold.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XNhZFGoPqP"
      },
      "source": [
        "## Tokenize et Pos Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "n9iBy8Rul1Iv",
        "outputId": "195b358a-369e-4d69-c35c-3a0d0c96aef7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>57</td>\n",
              "      <td>61</td>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kitchen</td>\n",
              "      <td>positive</td>\n",
              "      <td>55</td>\n",
              "      <td>62</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>menu</td>\n",
              "      <td>neutral</td>\n",
              "      <td>141</td>\n",
              "      <td>145</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3688</th>\n",
              "      <td>pot of boiling water</td>\n",
              "      <td>neutral</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>671</td>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>(Each, table, has, a, pot, of, boiling, water,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3689</th>\n",
              "      <td>meats</td>\n",
              "      <td>neutral</td>\n",
              "      <td>99</td>\n",
              "      <td>104</td>\n",
              "      <td>671</td>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>(Each, table, has, a, pot, of, boiling, water,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3690</th>\n",
              "      <td>vegetables</td>\n",
              "      <td>neutral</td>\n",
              "      <td>114</td>\n",
              "      <td>124</td>\n",
              "      <td>671</td>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>(Each, table, has, a, pot, of, boiling, water,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3691</th>\n",
              "      <td>rice</td>\n",
              "      <td>neutral</td>\n",
              "      <td>130</td>\n",
              "      <td>134</td>\n",
              "      <td>671</td>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>(Each, table, has, a, pot, of, boiling, water,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3692</th>\n",
              "      <td>glass noodles</td>\n",
              "      <td>neutral</td>\n",
              "      <td>139</td>\n",
              "      <td>152</td>\n",
              "      <td>671</td>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>(Each, table, has, a, pot, of, boiling, water,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3693 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      term  polarity from   to    id  \\\n",
              "0                    staff  negative    8   13  3121   \n",
              "1                     food  positive   57   61  2777   \n",
              "2                     food  positive    4    8  1634   \n",
              "3                  kitchen  positive   55   62  1634   \n",
              "4                     menu   neutral  141  145  1634   \n",
              "...                    ...       ...  ...  ...   ...   \n",
              "3688  pot of boiling water   neutral   17   37   671   \n",
              "3689                 meats   neutral   99  104   671   \n",
              "3690            vegetables   neutral  114  124   671   \n",
              "3691                  rice   neutral  130  134   671   \n",
              "3692         glass noodles   neutral  139  152   671   \n",
              "\n",
              "                                                   text  \\\n",
              "0                  But the staff was so horrible to us.   \n",
              "1     To be completely fair, the only redeeming fact...   \n",
              "2     The food is uniformly exceptional, with a very...   \n",
              "3     The food is uniformly exceptional, with a very...   \n",
              "4     The food is uniformly exceptional, with a very...   \n",
              "...                                                 ...   \n",
              "3688  Each table has a pot of boiling water sunken i...   \n",
              "3689  Each table has a pot of boiling water sunken i...   \n",
              "3690  Each table has a pot of boiling water sunken i...   \n",
              "3691  Each table has a pot of boiling water sunken i...   \n",
              "3692  Each table has a pot of boiling water sunken i...   \n",
              "\n",
              "                                             token_text  \n",
              "0       (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1     (To, be, completely, fair, ,, the, only, redee...  \n",
              "2     (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "3     (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "4     (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "...                                                 ...  \n",
              "3688  (Each, table, has, a, pot, of, boiling, water,...  \n",
              "3689  (Each, table, has, a, pot, of, boiling, water,...  \n",
              "3690  (Each, table, has, a, pot, of, boiling, water,...  \n",
              "3691  (Each, table, has, a, pot, of, boiling, water,...  \n",
              "3692  (Each, table, has, a, pot, of, boiling, water,...  \n",
              "\n",
              "[3693 rows x 7 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  TOKENIZE & POS TAG du TRAIN \n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "df_train['token_text'] = df_train.apply(lambda row: nlp(row[\"text\"]), axis=1)\n",
        "\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fsaj7FHTwt6",
        "outputId": "7354e02e-f7f8-49f4-eb13-872713c8ace6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['CCONJ', 'DET', 'NOUN', 'AUX', 'ADV', 'ADJ', 'ADP', 'PRON', 'PUNCT']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# on vérifie que les posTag ont bien été conservés\n",
        "df_train.token_text[0]\n",
        "[X.pos_ for X in  df_train.token_text[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KK2pjZH3qO7x",
        "outputId": "37120b38-c67f-409d-ef16-33ceeef60f11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pasta</td>\n",
              "      <td>positive</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>portions</td>\n",
              "      <td>positive</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>1579</td>\n",
              "      <td>And really large portions.</td>\n",
              "      <td>(And, really, large, portions, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>sardines with biscuits</td>\n",
              "      <td>positive</td>\n",
              "      <td>77</td>\n",
              "      <td>99</td>\n",
              "      <td>2912</td>\n",
              "      <td>The dishes offered were unique, very tasty and...</td>\n",
              "      <td>(The, dishes, offered, were, unique, ,, very, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>large whole shrimp</td>\n",
              "      <td>positive</td>\n",
              "      <td>101</td>\n",
              "      <td>119</td>\n",
              "      <td>2912</td>\n",
              "      <td>The dishes offered were unique, very tasty and...</td>\n",
              "      <td>(The, dishes, offered, were, unique, ,, very, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>pistachio ice cream</td>\n",
              "      <td>positive</td>\n",
              "      <td>135</td>\n",
              "      <td>154</td>\n",
              "      <td>2912</td>\n",
              "      <td>The dishes offered were unique, very tasty and...</td>\n",
              "      <td>(The, dishes, offered, were, unique, ,, very, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>office lunch</td>\n",
              "      <td>neutral</td>\n",
              "      <td>18</td>\n",
              "      <td>30</td>\n",
              "      <td>3188</td>\n",
              "      <td>Went there for an office lunch.</td>\n",
              "      <td>(Went, there, for, an, office, lunch, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>dinner</td>\n",
              "      <td>neutral</td>\n",
              "      <td>76</td>\n",
              "      <td>82</td>\n",
              "      <td>3041</td>\n",
              "      <td>We've only eaten in the restaurant once, but w...</td>\n",
              "      <td>(We, 've, only, eaten, in, the, restaurant, on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      term  polarity from   to    id  \\\n",
              "0               appetizers  positive    8   18   813   \n",
              "1                   salads  positive   23   29   813   \n",
              "2                    steak  positive   49   54   813   \n",
              "3                    pasta  positive   82   87   813   \n",
              "4                 portions  positive   17   25  1579   \n",
              "..                     ...       ...  ...  ...   ...   \n",
              "91  sardines with biscuits  positive   77   99  2912   \n",
              "92      large whole shrimp  positive  101  119  2912   \n",
              "93     pistachio ice cream  positive  135  154  2912   \n",
              "94            office lunch   neutral   18   30  3188   \n",
              "95                  dinner   neutral   76   82  3041   \n",
              "\n",
              "                                                 text  \\\n",
              "0   All the appetizers and salads were fabulous, t...   \n",
              "1   All the appetizers and salads were fabulous, t...   \n",
              "2   All the appetizers and salads were fabulous, t...   \n",
              "3   All the appetizers and salads were fabulous, t...   \n",
              "4                          And really large portions.   \n",
              "..                                                ...   \n",
              "91  The dishes offered were unique, very tasty and...   \n",
              "92  The dishes offered were unique, very tasty and...   \n",
              "93  The dishes offered were unique, very tasty and...   \n",
              "94                    Went there for an office lunch.   \n",
              "95  We've only eaten in the restaurant once, but w...   \n",
              "\n",
              "                                           token_text  \n",
              "0   (All, the, appetizers, and, salads, were, fabu...  \n",
              "1   (All, the, appetizers, and, salads, were, fabu...  \n",
              "2   (All, the, appetizers, and, salads, were, fabu...  \n",
              "3   (All, the, appetizers, and, salads, were, fabu...  \n",
              "4                   (And, really, large, portions, .)  \n",
              "..                                                ...  \n",
              "91  (The, dishes, offered, were, unique, ,, very, ...  \n",
              "92  (The, dishes, offered, were, unique, ,, very, ...  \n",
              "93  (The, dishes, offered, were, unique, ,, very, ...  \n",
              "94           (Went, there, for, an, office, lunch, .)  \n",
              "95  (We, 've, only, eaten, in, the, restaurant, on...  \n",
              "\n",
              "[96 rows x 7 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  TOKENIZE & POS TAG TEST GOLD \n",
        "df_testGold['token_text'] = df_testGold.apply(lambda row: nlp(row[\"text\"]), axis=1)\n",
        "\n",
        "df_testGold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Y5iXH5UKNG"
      },
      "source": [
        "## Partie Sentiments\n",
        "### Assignation de la polarité de chaque mot & Ajout des polarités dans les dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "qzZnSI55UfE5",
        "outputId": "3acbd812-b2b2-4934-9ae8-6a1f136eb495"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pasta</td>\n",
              "      <td>positive</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term  polarity from  to   id  \\\n",
              "0  appetizers  positive    8  18  813   \n",
              "1      salads  positive   23  29  813   \n",
              "2       steak  positive   49  54  813   \n",
              "3       pasta  positive   82  87  813   \n",
              "\n",
              "                                                text Score_by_word Sentiword  \\\n",
              "0  All the appetizers and salads were fabulous, t...                           \n",
              "1  All the appetizers and salads were fabulous, t...                           \n",
              "2  All the appetizers and salads were fabulous, t...                           \n",
              "3  All the appetizers and salads were fabulous, t...                           \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  \n",
              "3  (All, the, appetizers, and, salads, were, fabu...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assigner la polarité de chaque mot et les ajouter dans les dataframes\n",
        "\n",
        "df_train.insert(6,'Score_by_word',\"\")\n",
        "df_testGold.insert(6,'Score_by_word',\"\")\n",
        "\n",
        "df_train.insert(7,'Sentiword',\"\")\n",
        "df_testGold.insert(7,'Sentiword',\"\")\n",
        "\n",
        "df_testGold.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wa0WGjXjVeTJ"
      },
      "outputs": [],
      "source": [
        "def penn_to_wn(tag):\n",
        "  \"\"\"\n",
        "  Convertion des tags en simple WORDNET TAGS\n",
        "  \"\"\"\n",
        "  if tag.startswith('J'):\n",
        "    return wn.ADJ\n",
        "  elif tag.startswith('N'):\n",
        "    return wn.NOUN\n",
        "  elif tag.startswith('R'):\n",
        "    return wn.ADV\n",
        "  elif tag.startswith('V'):\n",
        "    return wn.VERB\n",
        "  return None\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# CHARGEMENT DES SENTIMENTS DETECTES\n",
        "def get_sentiment(word,tag):\n",
        "  \"\"\"\n",
        "  Return une liste de score positif negatif ou neutre et return une liste vide si le mot ne renvoie rien depuis senti wordnet.\n",
        "  \"\"\"\n",
        "  wn_tag = penn_to_wn(tag)\n",
        "  if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "    return []\n",
        "\n",
        "  lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "  if not lemma:\n",
        "    return []\n",
        "\n",
        "  synsets = wn.synsets(word, pos=wn_tag)\n",
        "  if not synsets:\n",
        "    return []\n",
        "\n",
        "  # Prend le premier sens du mot c'est à dire le sens le plus commun\n",
        "  synset = synsets[0]\n",
        "  swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "  return [swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "F_CAphzHXN6B",
        "outputId": "e682291d-bca8-48d7-a766-e08207488a04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...</td>\n",
              "      <td>[But, staff, horrible, us, .]</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>57</td>\n",
              "      <td>61</td>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...</td>\n",
              "      <td>[To, completely, fair, ,, redeeming, factor, f...</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kitchen</td>\n",
              "      <td>positive</td>\n",
              "      <td>55</td>\n",
              "      <td>62</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>menu</td>\n",
              "      <td>neutral</td>\n",
              "      <td>141</td>\n",
              "      <td>145</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>2846</td>\n",
              "      <td>Not only was the food outstanding, but the lit...</td>\n",
              "      <td>[[0.0, 0.625, 0.375], [0.0, 0.0, 1.0], [0.75, ...</td>\n",
              "      <td>[Not, food, outstanding, ,, little, 'perks, ',...</td>\n",
              "      <td>(Not, only, was, the, food, outstanding, ,, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>perks</td>\n",
              "      <td>positive</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>2846</td>\n",
              "      <td>Not only was the food outstanding, but the lit...</td>\n",
              "      <td>[[0.0, 0.625, 0.375], [0.0, 0.0, 1.0], [0.75, ...</td>\n",
              "      <td>[Not, food, outstanding, ,, little, 'perks, ',...</td>\n",
              "      <td>(Not, only, was, the, food, outstanding, ,, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>orrechiete with sausage and chicken</td>\n",
              "      <td>positive</td>\n",
              "      <td>27</td>\n",
              "      <td>62</td>\n",
              "      <td>1458</td>\n",
              "      <td>Our agreed favorite is the orrechiete with sau...</td>\n",
              "      <td>[[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...</td>\n",
              "      <td>[Our, agreed, favorite, orrechiete, sausage, c...</td>\n",
              "      <td>(Our, agreed, favorite, is, the, orrechiete, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>waiters</td>\n",
              "      <td>positive</td>\n",
              "      <td>76</td>\n",
              "      <td>83</td>\n",
              "      <td>1458</td>\n",
              "      <td>Our agreed favorite is the orrechiete with sau...</td>\n",
              "      <td>[[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...</td>\n",
              "      <td>[Our, agreed, favorite, orrechiete, sausage, c...</td>\n",
              "      <td>(Our, agreed, favorite, is, the, orrechiete, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>meats</td>\n",
              "      <td>neutral</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>1458</td>\n",
              "      <td>Our agreed favorite is the orrechiete with sau...</td>\n",
              "      <td>[[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...</td>\n",
              "      <td>[Our, agreed, favorite, orrechiete, sausage, c...</td>\n",
              "      <td>(Our, agreed, favorite, is, the, orrechiete, w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  term  polarity from   to    id  \\\n",
              "0                                staff  negative    8   13  3121   \n",
              "1                                 food  positive   57   61  2777   \n",
              "2                                 food  positive    4    8  1634   \n",
              "3                              kitchen  positive   55   62  1634   \n",
              "4                                 menu   neutral  141  145  1634   \n",
              "5                                 food  positive   17   21  2846   \n",
              "6                                perks  positive   51   56  2846   \n",
              "7  orrechiete with sausage and chicken  positive   27   62  1458   \n",
              "8                              waiters  positive   76   83  1458   \n",
              "9                                meats   neutral  152  157  1458   \n",
              "\n",
              "                                                text  \\\n",
              "0               But the staff was so horrible to us.   \n",
              "1  To be completely fair, the only redeeming fact...   \n",
              "2  The food is uniformly exceptional, with a very...   \n",
              "3  The food is uniformly exceptional, with a very...   \n",
              "4  The food is uniformly exceptional, with a very...   \n",
              "5  Not only was the food outstanding, but the lit...   \n",
              "6  Not only was the food outstanding, but the lit...   \n",
              "7  Our agreed favorite is the orrechiete with sau...   \n",
              "8  Our agreed favorite is the orrechiete with sau...   \n",
              "9  Our agreed favorite is the orrechiete with sau...   \n",
              "\n",
              "                                       Score_by_word  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...   \n",
              "1  [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   \n",
              "3  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   \n",
              "4  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   \n",
              "5  [[0.0, 0.625, 0.375], [0.0, 0.0, 1.0], [0.75, ...   \n",
              "6  [[0.0, 0.625, 0.375], [0.0, 0.0, 1.0], [0.75, ...   \n",
              "7  [[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...   \n",
              "8  [[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...   \n",
              "9  [[], [], [0.125, 0.0, 0.875], [], [0.25, 0.0, ...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0                      [But, staff, horrible, us, .]   \n",
              "1  [To, completely, fair, ,, redeeming, factor, f...   \n",
              "2  [The, food, uniformly, exceptional, ,, capable...   \n",
              "3  [The, food, uniformly, exceptional, ,, capable...   \n",
              "4  [The, food, uniformly, exceptional, ,, capable...   \n",
              "5  [Not, food, outstanding, ,, little, 'perks, ',...   \n",
              "6  [Not, food, outstanding, ,, little, 'perks, ',...   \n",
              "7  [Our, agreed, favorite, orrechiete, sausage, c...   \n",
              "8  [Our, agreed, favorite, orrechiete, sausage, c...   \n",
              "9  [Our, agreed, favorite, orrechiete, sausage, c...   \n",
              "\n",
              "                                          token_text  \n",
              "0    (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1  (To, be, completely, fair, ,, the, only, redee...  \n",
              "2  (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "3  (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "4  (The, food, is, uniformly, exceptional, ,, wit...  \n",
              "5  (Not, only, was, the, food, outstanding, ,, bu...  \n",
              "6  (Not, only, was, the, food, outstanding, ,, bu...  \n",
              "7  (Our, agreed, favorite, is, the, orrechiete, w...  \n",
              "8  (Our, agreed, favorite, is, the, orrechiete, w...  \n",
              "9  (Our, agreed, favorite, is, the, orrechiete, w...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# On remplit nos colonnes vides\n",
        "#  TRAIN DATAFRAME  #\n",
        "ps = PorterStemmer()\n",
        "i=0\n",
        "for token in df_train.text :\n",
        "    words_data= nltk.word_tokenize(str(token))\n",
        "    tokens_without_sw = [word for word in words_data if not word in stopwords.words()]\n",
        "\n",
        "\n",
        "    pos_val = nltk.pos_tag(tokens_without_sw)\n",
        "\n",
        "\n",
        "    scores = []\n",
        "    words_sentence = []\n",
        "\n",
        "    for (x,y) in pos_val :\n",
        "        scores.append(get_sentiment(x,y))\n",
        "        words_sentence.append(x)\n",
        "\n",
        "    df_train['Sentiword'][i] = words_sentence\n",
        "    df_train['Score_by_word'][i] = scores\n",
        "    i+=1\n",
        "\n",
        "df_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Kl-0SQtxZQF5",
        "outputId": "10088216-abe6-4d37-ce09-a3ad409583fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pasta</td>\n",
              "      <td>positive</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>portions</td>\n",
              "      <td>positive</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>1579</td>\n",
              "      <td>And really large portions.</td>\n",
              "      <td>[[], [0.625, 0.0, 0.375], [0.25, 0.125, 0.625]...</td>\n",
              "      <td>[And, really, large, portions, .]</td>\n",
              "      <td>(And, really, large, portions, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sweet lassi</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>2882</td>\n",
              "      <td>The sweet lassi was excellent as was the lamb ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[The, sweet, lassi, excellent, lamb, chettinad...</td>\n",
              "      <td>(The, sweet, lassi, was, excellent, as, was, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lamb chettinad</td>\n",
              "      <td>positive</td>\n",
              "      <td>41</td>\n",
              "      <td>55</td>\n",
              "      <td>2882</td>\n",
              "      <td>The sweet lassi was excellent as was the lamb ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[The, sweet, lassi, excellent, lamb, chettinad...</td>\n",
              "      <td>(The, sweet, lassi, was, excellent, as, was, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>garlic naan</td>\n",
              "      <td>positive</td>\n",
              "      <td>64</td>\n",
              "      <td>75</td>\n",
              "      <td>2882</td>\n",
              "      <td>The sweet lassi was excellent as was the lamb ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[The, sweet, lassi, excellent, lamb, chettinad...</td>\n",
              "      <td>(The, sweet, lassi, was, excellent, as, was, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rasamalai</td>\n",
              "      <td>negative</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>2882</td>\n",
              "      <td>The sweet lassi was excellent as was the lamb ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[The, sweet, lassi, excellent, lamb, chettinad...</td>\n",
              "      <td>(The, sweet, lassi, was, excellent, as, was, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Service</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1609</td>\n",
              "      <td>Service was quick.</td>\n",
              "      <td>[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], []]</td>\n",
              "      <td>[Service, quick, .]</td>\n",
              "      <td>(Service, was, quick, .)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             term  polarity from  to    id  \\\n",
              "0      appetizers  positive    8  18   813   \n",
              "1          salads  positive   23  29   813   \n",
              "2           steak  positive   49  54   813   \n",
              "3           pasta  positive   82  87   813   \n",
              "4        portions  positive   17  25  1579   \n",
              "5     sweet lassi  positive    4  15  2882   \n",
              "6  lamb chettinad  positive   41  55  2882   \n",
              "7     garlic naan  positive   64  75  2882   \n",
              "8       rasamalai  negative   84  93  2882   \n",
              "9         Service  positive    0   7  1609   \n",
              "\n",
              "                                                text  \\\n",
              "0  All the appetizers and salads were fabulous, t...   \n",
              "1  All the appetizers and salads were fabulous, t...   \n",
              "2  All the appetizers and salads were fabulous, t...   \n",
              "3  All the appetizers and salads were fabulous, t...   \n",
              "4                         And really large portions.   \n",
              "5  The sweet lassi was excellent as was the lamb ...   \n",
              "6  The sweet lassi was excellent as was the lamb ...   \n",
              "7  The sweet lassi was excellent as was the lamb ...   \n",
              "8  The sweet lassi was excellent as was the lamb ...   \n",
              "9                                 Service was quick.   \n",
              "\n",
              "                                       Score_by_word  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "1  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "3  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "4  [[], [0.625, 0.0, 0.375], [0.25, 0.125, 0.625]...   \n",
              "5  [[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....   \n",
              "6  [[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....   \n",
              "7  [[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....   \n",
              "8  [[], [0.0, 0.0, 1.0], [], [1.0, 0.0, 0.0], [0....   \n",
              "9             [[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], []]   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "1  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "2  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "3  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "4                  [And, really, large, portions, .]   \n",
              "5  [The, sweet, lassi, excellent, lamb, chettinad...   \n",
              "6  [The, sweet, lassi, excellent, lamb, chettinad...   \n",
              "7  [The, sweet, lassi, excellent, lamb, chettinad...   \n",
              "8  [The, sweet, lassi, excellent, lamb, chettinad...   \n",
              "9                                [Service, quick, .]   \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  \n",
              "3  (All, the, appetizers, and, salads, were, fabu...  \n",
              "4                  (And, really, large, portions, .)  \n",
              "5  (The, sweet, lassi, was, excellent, as, was, t...  \n",
              "6  (The, sweet, lassi, was, excellent, as, was, t...  \n",
              "7  (The, sweet, lassi, was, excellent, as, was, t...  \n",
              "8  (The, sweet, lassi, was, excellent, as, was, t...  \n",
              "9                           (Service, was, quick, .)  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# On remplit nos  colonnes vides\n",
        "#  TEST DATAFRAME  #\n",
        "ps = PorterStemmer()\n",
        "i=0\n",
        "for token in df_testGold.text :\n",
        "    words_data= nltk.word_tokenize(str(token))\n",
        "    tokens_without_sw = [word for word in words_data if not word in stopwords.words()]\n",
        "\n",
        "\n",
        "    pos_val = nltk.pos_tag(tokens_without_sw)\n",
        "\n",
        "\n",
        "    scores = []\n",
        "    words_sentence = []\n",
        "\n",
        "    for (x,y) in pos_val :\n",
        "        scores.append(get_sentiment(x,y))\n",
        "        words_sentence.append(x)\n",
        "\n",
        "    df_testGold['Sentiword'][i] = words_sentence\n",
        "    df_testGold['Score_by_word'][i] = scores\n",
        "    i+=1\n",
        "\n",
        "df_testGold.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CgtuhDj3Zqb2",
        "outputId": "3284c6f7-34bc-4dde-9457-036f9b53619d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td></td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td></td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td></td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term  polarity from  to   id  \\\n",
              "0  appetizers  positive    8  18  813   \n",
              "1      salads  positive   23  29  813   \n",
              "2       steak  positive   49  54  813   \n",
              "\n",
              "                                                text  \\\n",
              "0  All the appetizers and salads were fabulous, t...   \n",
              "1  All the appetizers and salads were fabulous, t...   \n",
              "2  All the appetizers and salads were fabulous, t...   \n",
              "\n",
              "                                       Score_by_word PosTag  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...          \n",
              "1  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...          \n",
              "2  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...          \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "1  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "2  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# On ajoute une colonne avec seulement les POStag\n",
        "# (il est plus facile de retirer des colonnes que d'en ajouter plus tard)\n",
        "\n",
        "df_train.insert(7,'PosTag',\"\")\n",
        "df_testGold.insert(7,'PosTag',\"\")\n",
        "\n",
        "df_testGold.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xRSnFYPJZ5fk"
      },
      "outputs": [],
      "source": [
        "# On remplit \n",
        "for i in range(len(df_train.PosTag)):\n",
        "    df_train['PosTag'][i] = [(X.pos_) for X in  df_train.token_text[i]]\n",
        "\n",
        "for i in range(len(df_testGold.PosTag)):\n",
        "    df_testGold['PosTag'][i] = [(X.pos_) for X in  df_testGold.token_text[i]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Okl38WcMaKt0",
        "outputId": "94bdf6d1-8571-46a8-9fc1-76c389936a0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...</td>\n",
              "      <td>[CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...</td>\n",
              "      <td>[But, staff, horrible, us, .]</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>57</td>\n",
              "      <td>61</td>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...</td>\n",
              "      <td>[PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...</td>\n",
              "      <td>[To, completely, fair, ,, redeeming, factor, f...</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>[DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    term  polarity from  to    id  \\\n",
              "0  staff  negative    8  13  3121   \n",
              "1   food  positive   57  61  2777   \n",
              "2   food  positive    4   8  1634   \n",
              "\n",
              "                                                text  \\\n",
              "0               But the staff was so horrible to us.   \n",
              "1  To be completely fair, the only redeeming fact...   \n",
              "2  The food is uniformly exceptional, with a very...   \n",
              "\n",
              "                                       Score_by_word  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...   \n",
              "1  [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...   \n",
              "1  [PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...   \n",
              "2  [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0                      [But, staff, horrible, us, .]   \n",
              "1  [To, completely, fair, ,, redeeming, factor, f...   \n",
              "2  [The, food, uniformly, exceptional, ,, capable...   \n",
              "\n",
              "                                          token_text  \n",
              "0    (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1  (To, be, completely, fair, ,, the, only, redee...  \n",
              "2  (The, food, is, uniformly, exceptional, ,, wit...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "vJ07DR7waLNx",
        "outputId": "fa65fc3f-0cc0-4594-84c3-fcb621d8cd6e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>positive</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>positive</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>813</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term  polarity from  to   id  \\\n",
              "0  appetizers  positive    8  18  813   \n",
              "1      salads  positive   23  29  813   \n",
              "2       steak  positive   49  54  813   \n",
              "\n",
              "                                                text  \\\n",
              "0  All the appetizers and salads were fabulous, t...   \n",
              "1  All the appetizers and salads were fabulous, t...   \n",
              "2  All the appetizers and salads were fabulous, t...   \n",
              "\n",
              "                                       Score_by_word  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "1  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "1  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "2  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "1  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "2  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_testGold.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtkCTTVkbhbA"
      },
      "source": [
        "### Tri dans les dataframes\n",
        "#### Colonnes à conserver\n",
        "* Variables explicatives/prédictives :\n",
        "  * term\n",
        "  * text\n",
        "  * Score_by_word\n",
        "  * PosTag\n",
        "  * Sentiword\n",
        "* Label à prédire :\n",
        "  * polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VSo8PG0fbfvQ",
        "outputId": "b754967b-bc03-4af3-86c4-b432373a162a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>polarity</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...</td>\n",
              "      <td>[But, staff, horrible, us, .]</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...</td>\n",
              "      <td>negative</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...</td>\n",
              "      <td>[To, completely, fair, ,, redeeming, factor, f...</td>\n",
              "      <td>[[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    term                                               text  \\\n",
              "0  staff               But the staff was so horrible to us.   \n",
              "1   food  To be completely fair, the only redeeming fact...   \n",
              "2   food  The food is uniformly exceptional, with a very...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...   \n",
              "1  [PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...   \n",
              "2  [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0                      [But, staff, horrible, us, .]   \n",
              "1  [To, completely, fair, ,, redeeming, factor, f...   \n",
              "2  [The, food, uniformly, exceptional, ,, capable...   \n",
              "\n",
              "                                       Score_by_word  polarity  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...  negative   \n",
              "1  [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...  positive   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...  positive   \n",
              "\n",
              "                                          token_text  \n",
              "0    (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1  (To, be, completely, fair, ,, the, only, redee...  \n",
              "2  (The, food, is, uniformly, exceptional, ,, wit...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  TRAIN DATAFRAME  #\n",
        "DF_train = df_train[['term','text','PosTag','Sentiword','Score_by_word','polarity','token_text']]\n",
        "DF_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8qGInO5JcP5S",
        "outputId": "0557a81b-547b-42b0-c334-aa4ccba71835"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>polarity</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term                                               text  \\\n",
              "0  appetizers  All the appetizers and salads were fabulous, t...   \n",
              "1      salads  All the appetizers and salads were fabulous, t...   \n",
              "2       steak  All the appetizers and salads were fabulous, t...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "1  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "2  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "1  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "2  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "\n",
              "                                       Score_by_word  polarity  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "1  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  TEST DATAFRAME  #\n",
        "DF_test = df_testGold[['term','text','PosTag','Sentiword','Score_by_word','polarity','token_text']]\n",
        "DF_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dZ3p7xUEcbkY",
        "outputId": "981db482-b2cf-4085-ce90-7fecf300c802"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...</td>\n",
              "      <td>[CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...</td>\n",
              "      <td>[But, staff, horrible, us, .]</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>57</td>\n",
              "      <td>61</td>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...</td>\n",
              "      <td>[PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...</td>\n",
              "      <td>[To, completely, fair, ,, redeeming, factor, f...</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>[DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    term  polarity from  to    id  \\\n",
              "0  staff  negative    8  13  3121   \n",
              "1   food  positive   57  61  2777   \n",
              "2   food  positive    4   8  1634   \n",
              "\n",
              "                                                text  \\\n",
              "0               But the staff was so horrible to us.   \n",
              "1  To be completely fair, the only redeeming fact...   \n",
              "2  The food is uniformly exceptional, with a very...   \n",
              "\n",
              "                                       Score_by_word  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...   \n",
              "1  [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...   \n",
              "1  [PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...   \n",
              "2  [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0                      [But, staff, horrible, us, .]   \n",
              "1  [To, completely, fair, ,, redeeming, factor, f...   \n",
              "2  [The, food, uniformly, exceptional, ,, capable...   \n",
              "\n",
              "                                          token_text  \n",
              "0    (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1  (To, be, completely, fair, ,, the, only, redee...  \n",
              "2  (The, food, is, uniformly, exceptional, ,, wit...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sauvegarder en Dataframe grace à .pkl\n",
        "df_train.to_pickle('df_train_PANDAS_DATAFRAME.pkl')  \n",
        "df_testGold.to_pickle('df_test_PANDAS_DATAFRAME.pkl')\n",
        "\n",
        "#Pour recharger les dataframe : \n",
        "df_train = pd.read_pickle('df_train_PANDAS_DATAFRAME.pkl')\n",
        "df_testGold = pd.read_pickle('df_test_PANDAS_DATAFRAME.pkl')\n",
        "\n",
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaUA4kxkcz9k"
      },
      "source": [
        "## Visualisation\n",
        "Générer une visualisation des données à travers des graphiques pour montrer combien de mots ont une polarité positive / negative dans chaque fichier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2gR9JyYc-Zc"
      },
      "source": [
        "### Repartition de la polarite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "SlmE7Pvbc8wJ",
        "outputId": "2621d709-2503-470e-f6b5-d67fe1f92f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 805.,    0.,    0., 2164.,    0.,    0.,  633.,    0.,    0.,\n",
              "           91.],\n",
              "        [  18.,    0.,    0.,   68.,    0.,    0.,   10.,    0.,    0.,\n",
              "            0.]]),\n",
              " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
              " <a list of 2 BarContainer objects>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x1 = DF_train['polarity']\n",
        "x2 = DF_test['polarity']\n",
        "\n",
        "# on assigne une couleur unique (plus lisible sur le graphique)\n",
        "colors = ['#E69F00', '#56B4E9']\n",
        "names = ['TRAIN', 'TEST']\n",
        "         \n",
        "\n",
        "plt.hist([x1, x2],color = colors, label=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tIzcnpSdtWa"
      },
      "source": [
        "Les nombres n'étant pas très pertinents pour étudier la répartition nous regarderons plutôt le pourcentage. De plus le pourcentage offre une meilleure visualisation de la répartition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSx7qmn0dqht",
        "outputId": "450445ad-a5f0-49e2-ec47-a94bb4b6161f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### TRAIN ###\n",
            "Nombre de positif :  2164 , Nombre de negatif :  805 , Nombre de neutre :  633 , Nombre de conflits :  91\n",
            "### TEST ###\n",
            "Nombre de positif :  68 , Nombre de negatif :  18 , Nombre de neutre :  10 , Nombre de conflits :  0\n",
            "### TRAIN ###\n",
            "Positive :  58.59734633089629  %, Negative :  21.797996209044136  %, Neutral :  17.140536149471973  %, Conflicts :  2.464121310587598  %\n",
            "### TEST ###\n",
            "Positive :  70.83333333333334  %, Negative :  18.75  %, Neutral :  10.416666666666668  %, Conflicts :  0.0  %\n"
          ]
        }
      ],
      "source": [
        "# NOMBRES\n",
        "## TRAIN\n",
        "posTrain=len(DF_train[DF_train['polarity'] == 'positive' ].index)\n",
        "negTrain=len(DF_train[DF_train['polarity'] == 'negative' ].index)\n",
        "neuTrain=len(DF_train[DF_train['polarity'] == 'neutral' ].index)\n",
        "confTrain=len(DF_train[DF_train['polarity'] == 'conflict' ].index)\n",
        "\n",
        "## TEST\n",
        "posTest=len(DF_test[DF_test['polarity'] == 'positive' ].index)\n",
        "negTest=len(DF_test[DF_test['polarity'] == 'negative' ].index)\n",
        "neuTest=len(DF_test[DF_test['polarity'] == 'neutral' ].index)\n",
        "confTest=len(DF_test[DF_test['polarity'] == 'conflict' ].index)\n",
        "\n",
        "print(\"### TRAIN ###\")\n",
        "print(\"Nombre de positif : \",posTrain,\", Nombre de negatif : \",negTrain,\", Nombre de neutre : \",neuTrain,\", Nombre de conflits : \",confTrain)\n",
        "print(\"### TEST ###\")\n",
        "print(\"Nombre de positif : \",posTest,\", Nombre de negatif : \",negTest,\", Nombre de neutre : \",neuTest,\", Nombre de conflits : \",confTest)\n",
        "\n",
        "# TAUX\n",
        "## TRAIN\n",
        "pos_train=len(DF_train[DF_train['polarity'] == 'positive' ].index)/len(DF_train)*100\n",
        "neg_train=len(DF_train[DF_train['polarity'] == 'negative' ].index)/len(DF_train)*100\n",
        "neu_train=len(DF_train[DF_train['polarity'] == 'neutral' ].index)/len(DF_train)*100\n",
        "conf_train=len(DF_train[DF_train['polarity'] == 'conflict' ].index)/len(DF_train)*100\n",
        "\n",
        "## TEST\n",
        "pos_test=len(DF_test[DF_test['polarity'] == 'positive' ].index)/len(DF_test)*100\n",
        "neg_test=len(DF_test[DF_test['polarity'] == 'negative' ].index)/len(DF_test)*100\n",
        "neu_test=len(DF_test[DF_test['polarity'] == 'neutral' ].index)/len(DF_test)*100\n",
        "conf_test=len(DF_test[DF_test['polarity'] == 'conflict' ].index)/len(DF_test)*100\n",
        "\n",
        "print(\"### TRAIN ###\")\n",
        "print(\"Positive : \",pos_train,\" %, Negative : \",neg_train,\" %, Neutral : \",neu_train,\" %, Conflicts : \",conf_train, \" %\")\n",
        "print(\"### TEST ###\")\n",
        "print(\"Positive : \",pos_test,\" %, Negative : \",neg_test,\" %, Neutral : \",neu_test,\" %, Conflicts : \",conf_test, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "GjpTCzq8dsmI",
        "outputId": "a01358b7-80ea-4f8d-dfd6-3610bfa2513f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Répartition en % des données en fonctions de leurs polarités ')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Affichage au format Histogramme\n",
        "barWidth = 0.4\n",
        "train = [pos_train, neg_train, neu_train, conf_train]\n",
        "test = [pos_test, neg_test, neu_test, conf_test]\n",
        "r1 = range(len(train))\n",
        "r2 = [x + barWidth for x in r1]\n",
        "\n",
        "plotTrain= plt.bar(r1, train, width = barWidth, color = ['red' for i in train])\n",
        "plotTest= plt.bar(r2, test, width = barWidth, color = ['blue' for i in train])\n",
        "plt.xticks([r + barWidth / 2 for r in range(len(train))], ['positive', 'negative', 'neutral','conflict'])\n",
        "plt.legend([plotTrain, plotTest], ['TRAIN', 'TEST'])\n",
        "plt.xlabel(\"Polarité\")\n",
        "plt.ylabel(\"Répartition en %\")\n",
        "plt.title(\"Répartition en % des données en fonctions de leurs polarités \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwKnTGQBgMcX"
      },
      "source": [
        "Il n'y a pas de \"conflict\" dans l'ensemble de test, on ne prendra donc pas en compte ces valeurs.\n",
        "\n",
        "Cependant, les autres classes semblents, d'après le graph, bien réparties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFJMmy7ZgMPR",
        "outputId": "c6d8e75b-166b-4e19-8c92-d51e0fa131d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "F:\\COURS\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "# On récupère les indexes qui contiennent des \"conflicts\"\n",
        "indexNames = DF_train[DF_train['polarity'] == 'conflict' ].index\n",
        "# on retire les lignes concernées\n",
        "DF_train.drop(indexNames , inplace=True)\n",
        "\n",
        "# On récupère les indexes qui contiennent des \"conflicts\"\n",
        "indexNames = DF_test[DF_test['polarity'] == 'conflict' ].index\n",
        "# on retire les lignes concernées\n",
        "DF_test.drop(indexNames , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rr6XYIzdgkcx"
      },
      "outputs": [],
      "source": [
        "# On récupère les indexes qui contiennent des \"conflicts\"\n",
        "indexNames = DF_train[DF_train['polarity'] == 'conflict' ].index\n",
        "\n",
        "# On récupère les indexes qui contiennent des \"conflicts\"\n",
        "indexNames = DF_test[DF_test['polarity'] == 'conflict' ].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "svzbhW4Ag4zt"
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "DF_train.to_pickle('DF_train_PANDAS_DATAFRAME.pkl')  \n",
        "DF_test.to_pickle('DF_test_PANDAS_DATAFRAME.pkl')  \n",
        "\n",
        "#Pour recharger les dataframe : \n",
        "DF_train = pd.read_pickle('DF_train_PANDAS_DATAFRAME.pkl')\n",
        "DF_test = pd.read_pickle('DF_test_PANDAS_DATAFRAME.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "o4rDYVgdhGrk",
        "outputId": "351a3c84-3ac1-4507-954d-b77fcf41698d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>polarity</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>staff</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...</td>\n",
              "      <td>[But, staff, horrible, us, .]</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...</td>\n",
              "      <td>negative</td>\n",
              "      <td>(But, the, staff, was, so, horrible, to, us, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>food</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...</td>\n",
              "      <td>[To, completely, fair, ,, redeeming, factor, f...</td>\n",
              "      <td>[[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(To, be, completely, fair, ,, the, only, redee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...</td>\n",
              "      <td>[The, food, uniformly, exceptional, ,, capable...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(The, food, is, uniformly, exceptional, ,, wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    term                                               text  \\\n",
              "0  staff               But the staff was so horrible to us.   \n",
              "1   food  To be completely fair, the only redeeming fact...   \n",
              "2   food  The food is uniformly exceptional, with a very...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...   \n",
              "1  [PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...   \n",
              "2  [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0                      [But, staff, horrible, us, .]   \n",
              "1  [To, completely, fair, ,, redeeming, factor, f...   \n",
              "2  [The, food, uniformly, exceptional, ,, capable...   \n",
              "\n",
              "                                       Score_by_word  polarity  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...  negative   \n",
              "1  [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...  positive   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...  positive   \n",
              "\n",
              "                                          token_text  \n",
              "0    (But, the, staff, was, so, horrible, to, us, .)  \n",
              "1  (To, be, completely, fair, ,, the, only, redee...  \n",
              "2  (The, food, is, uniformly, exceptional, ,, wit...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DF_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "QbOSppFDhMDQ",
        "outputId": "3d92faca-4299-42dc-94a7-a236fffed280"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>PosTag</th>\n",
              "      <th>Sentiword</th>\n",
              "      <th>Score_by_word</th>\n",
              "      <th>polarity</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>appetizers</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salads</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steak</td>\n",
              "      <td>All the appetizers and salads were fabulous, t...</td>\n",
              "      <td>[DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...</td>\n",
              "      <td>[All, appetizers, salads, fabulous, ,, steak, ...</td>\n",
              "      <td>[[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...</td>\n",
              "      <td>positive</td>\n",
              "      <td>(All, the, appetizers, and, salads, were, fabu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         term                                               text  \\\n",
              "0  appetizers  All the appetizers and salads were fabulous, t...   \n",
              "1      salads  All the appetizers and salads were fabulous, t...   \n",
              "2       steak  All the appetizers and salads were fabulous, t...   \n",
              "\n",
              "                                              PosTag  \\\n",
              "0  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "1  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "2  [DET, DET, NOUN, CCONJ, NOUN, AUX, ADJ, PUNCT,...   \n",
              "\n",
              "                                           Sentiword  \\\n",
              "0  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "1  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "2  [All, appetizers, salads, fabulous, ,, steak, ...   \n",
              "\n",
              "                                       Score_by_word  polarity  \\\n",
              "0  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "1  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "2  [[], [0.0, 0.0, 1.0], [], [0.875, 0.125, 0.0],...  positive   \n",
              "\n",
              "                                          token_text  \n",
              "0  (All, the, appetizers, and, salads, were, fabu...  \n",
              "1  (All, the, appetizers, and, salads, were, fabu...  \n",
              "2  (All, the, appetizers, and, salads, were, fabu...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DF_test.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lB3dqKHhcMM"
      },
      "source": [
        "### Conversion des dataframes en listes\n",
        "Cela va permettre la vectorisation par la suite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvZ4vbOMjx6d",
        "outputId": "968ced96-fbce-4c98-c32a-00c007d7bb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame after reset_index:\n"
          ]
        }
      ],
      "source": [
        "print(\"DataFrame after reset_index:\")\n",
        "DF_train.reset_index(inplace=True, drop=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk5419Z8hSVr",
        "outputId": "169bf902-5fd7-48c6-b3d2-7bc34e8ce5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      index                  term  \\\n",
            "0         0                 staff   \n",
            "1         1                  food   \n",
            "2         2                  food   \n",
            "3         3               kitchen   \n",
            "4         4                  menu   \n",
            "...     ...                   ...   \n",
            "3597   3688  pot of boiling water   \n",
            "3598   3689                 meats   \n",
            "3599   3690            vegetables   \n",
            "3600   3691                  rice   \n",
            "3601   3692         glass noodles   \n",
            "\n",
            "                                                   text  \\\n",
            "0                  But the staff was so horrible to us.   \n",
            "1     To be completely fair, the only redeeming fact...   \n",
            "2     The food is uniformly exceptional, with a very...   \n",
            "3     The food is uniformly exceptional, with a very...   \n",
            "4     The food is uniformly exceptional, with a very...   \n",
            "...                                                 ...   \n",
            "3597  Each table has a pot of boiling water sunken i...   \n",
            "3598  Each table has a pot of boiling water sunken i...   \n",
            "3599  Each table has a pot of boiling water sunken i...   \n",
            "3600  Each table has a pot of boiling water sunken i...   \n",
            "3601  Each table has a pot of boiling water sunken i...   \n",
            "\n",
            "                                                 PosTag  \\\n",
            "0     [CCONJ, DET, NOUN, AUX, ADV, ADJ, ADP, PRON, P...   \n",
            "1     [PART, AUX, ADV, ADJ, PUNCT, DET, ADJ, VERB, N...   \n",
            "2     [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
            "3     [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
            "4     [DET, NOUN, AUX, ADV, ADJ, PUNCT, ADP, DET, AD...   \n",
            "...                                                 ...   \n",
            "3597  [DET, NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, ...   \n",
            "3598  [DET, NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, ...   \n",
            "3599  [DET, NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, ...   \n",
            "3600  [DET, NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, ...   \n",
            "3601  [DET, NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, ...   \n",
            "\n",
            "                                              Sentiword  \\\n",
            "0                         [But, staff, horrible, us, .]   \n",
            "1     [To, completely, fair, ,, redeeming, factor, f...   \n",
            "2     [The, food, uniformly, exceptional, ,, capable...   \n",
            "3     [The, food, uniformly, exceptional, ,, capable...   \n",
            "4     [The, food, uniformly, exceptional, ,, capable...   \n",
            "...                                                 ...   \n",
            "3597  [Each, table, boiling, water, sunken, surface,...   \n",
            "3598  [Each, table, boiling, water, sunken, surface,...   \n",
            "3599  [Each, table, boiling, water, sunken, surface,...   \n",
            "3600  [Each, table, boiling, water, sunken, surface,...   \n",
            "3601  [Each, table, boiling, water, sunken, surface,...   \n",
            "\n",
            "                                          Score_by_word  polarity  \\\n",
            "0     [[], [0.0, 0.0, 1.0], [0.0, 0.625, 0.375], [],...  negative   \n",
            "1     [[], [0.5, 0.0, 0.5], [0.625, 0.0, 0.375], [],...  positive   \n",
            "2     [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...  positive   \n",
            "3     [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...  positive   \n",
            "4     [[], [0.0, 0.0, 1.0], [], [], [], [0.125, 0.0,...   neutral   \n",
            "...                                                 ...       ...   \n",
            "3597  [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0....   neutral   \n",
            "3598  [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0....   neutral   \n",
            "3599  [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0....   neutral   \n",
            "3600  [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0....   neutral   \n",
            "3601  [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0....   neutral   \n",
            "\n",
            "                                             token_text  \n",
            "0       (But, the, staff, was, so, horrible, to, us, .)  \n",
            "1     (To, be, completely, fair, ,, the, only, redee...  \n",
            "2     (The, food, is, uniformly, exceptional, ,, wit...  \n",
            "3     (The, food, is, uniformly, exceptional, ,, wit...  \n",
            "4     (The, food, is, uniformly, exceptional, ,, wit...  \n",
            "...                                                 ...  \n",
            "3597  (Each, table, has, a, pot, of, boiling, water,...  \n",
            "3598  (Each, table, has, a, pot, of, boiling, water,...  \n",
            "3599  (Each, table, has, a, pot, of, boiling, water,...  \n",
            "3600  (Each, table, has, a, pot, of, boiling, water,...  \n",
            "3601  (Each, table, has, a, pot, of, boiling, water,...  \n",
            "\n",
            "[3602 rows x 8 columns]\n",
            "[['staff' 'But the staff was so horrible to us.'\n",
            "  'CCONJ DET NOUN AUX ADV ADJ ADP PRON PUNCT' 'But staff horrible us .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.625, 0.375],[],[]']\n",
            " ['food'\n",
            "  \"To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora.\"\n",
            "  'PART AUX ADV ADJ PUNCT DET ADJ VERB NOUN AUX DET NOUN PUNCT PRON AUX ADP ADJ PUNCT CCONJ AUX PART VERB ADP ADP DET DET ADJ NOUN ADP PROPN PUNCT'\n",
            "  \"To completely fair , redeeming factor food , average , could n't make deficiencies Teodora .\"\n",
            "  '[],[0.5, 0.0, 0.5],[0.625, 0.0, 0.375],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[],[],[],[0.125, 0.125, 0.75],[],[]']\n",
            " ['food'\n",
            "  \"The food is uniformly exceptional, with a very capable kitchen which will proudly whip up whatever you feel like eating, whether it's on the menu or not.\"\n",
            "  'DET NOUN AUX ADV ADJ PUNCT ADP DET ADV ADJ NOUN PRON AUX ADV VERB ADP PRON PRON VERB ADP VERB PUNCT SCONJ PRON AUX ADP DET NOUN CCONJ PART PUNCT'\n",
            "  \"The food uniformly exceptional , capable kitchen proudly whip whatever feel like eating , whether 's menu .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[],[],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[],[],[],[],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ...\n",
            " ['vegetables'\n",
            "  'Each table has a pot of boiling water sunken into its surface, and you get platters of thin sliced meats, various vegetables, and rice and glass noodles.'\n",
            "  'DET NOUN VERB DET NOUN ADP NOUN NOUN VERB ADP PRON NOUN PUNCT CCONJ PRON VERB NOUN ADP ADJ VERB NOUN PUNCT ADJ NOUN PUNCT CCONJ NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'Each table boiling water sunken surface , get platters thin sliced meats , various vegetables , rice glass noodles .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[0.125, 0.375, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['rice'\n",
            "  'Each table has a pot of boiling water sunken into its surface, and you get platters of thin sliced meats, various vegetables, and rice and glass noodles.'\n",
            "  'DET NOUN VERB DET NOUN ADP NOUN NOUN VERB ADP PRON NOUN PUNCT CCONJ PRON VERB NOUN ADP ADJ VERB NOUN PUNCT ADJ NOUN PUNCT CCONJ NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'Each table boiling water sunken surface , get platters thin sliced meats , various vegetables , rice glass noodles .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[0.125, 0.375, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['glass noodles'\n",
            "  'Each table has a pot of boiling water sunken into its surface, and you get platters of thin sliced meats, various vegetables, and rice and glass noodles.'\n",
            "  'DET NOUN VERB DET NOUN ADP NOUN NOUN VERB ADP PRON NOUN PUNCT CCONJ PRON VERB NOUN ADP ADJ VERB NOUN PUNCT ADJ NOUN PUNCT CCONJ NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'Each table boiling water sunken surface , get platters thin sliced meats , various vegetables , rice glass noodles .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[0.125, 0.375, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']]\n"
          ]
        }
      ],
      "source": [
        "# TRAIN DATASET\n",
        "df_train = DF_train\n",
        "\n",
        "list_train = []\n",
        "label_train = []\n",
        "print(df_train)\n",
        "for i in range(len(df_train)):\n",
        "    pos_tag = [X.pos_ for X in  df_train.token_text[i]]\n",
        "    pos_tag_text = \" \".join(pos_tag)\n",
        "    senti_word = \" \".join(df_train.Sentiword[i])\n",
        "    score_by_word = \",\".join(str(v) for v in df_train.Score_by_word[i])\n",
        "    \n",
        "    list_train.append(\n",
        "        (df_train.term[i],\n",
        "        df_train.text[i],\n",
        "        pos_tag_text,\n",
        "        senti_word,\n",
        "        score_by_word,\n",
        "        ))\n",
        "    label_train.append(df_train.polarity[i])\n",
        "\n",
        "list_train\n",
        "\n",
        "Restaurant_Train = np.array(list_train)\n",
        "print(Restaurant_Train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5VdObBfkA1u",
        "outputId": "e255474c-246a-4565-d657-e71bf89b35b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['appetizers'\n",
            "  'All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!'\n",
            "  'DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT'\n",
            "  'All appetizers salads fabulous , steak mouth watering pasta delicious ! ! !'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]']\n",
            " ['salads'\n",
            "  'All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!'\n",
            "  'DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT'\n",
            "  'All appetizers salads fabulous , steak mouth watering pasta delicious ! ! !'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]']\n",
            " ['steak'\n",
            "  'All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!'\n",
            "  'DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT'\n",
            "  'All appetizers salads fabulous , steak mouth watering pasta delicious ! ! !'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]']\n",
            " ['pasta'\n",
            "  'All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!'\n",
            "  'DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT'\n",
            "  'All appetizers salads fabulous , steak mouth watering pasta delicious ! ! !'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]']\n",
            " ['portions' 'And really large portions.' 'CCONJ ADV ADJ NOUN PUNCT'\n",
            "  'And really large portions .'\n",
            "  '[],[0.625, 0.0, 0.375],[0.25, 0.125, 0.625],[0.0, 0.0, 1.0],[]']\n",
            " ['sweet lassi'\n",
            "  'The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.'\n",
            "  'DET ADJ PROPN AUX ADJ SCONJ AUX DET NOUN NOUN CCONJ DET NOUN PROPN CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'The sweet lassi excellent lamb chettinad garlic naan rasamalai forgettable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[1.0, 0.0, 0.0],[0.0, 0.0, 1.0],[],[],[],[],[0.5, 0.0, 0.5],[]']\n",
            " ['lamb chettinad'\n",
            "  'The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.'\n",
            "  'DET ADJ PROPN AUX ADJ SCONJ AUX DET NOUN NOUN CCONJ DET NOUN PROPN CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'The sweet lassi excellent lamb chettinad garlic naan rasamalai forgettable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[1.0, 0.0, 0.0],[0.0, 0.0, 1.0],[],[],[],[],[0.5, 0.0, 0.5],[]']\n",
            " ['garlic naan'\n",
            "  'The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.'\n",
            "  'DET ADJ PROPN AUX ADJ SCONJ AUX DET NOUN NOUN CCONJ DET NOUN PROPN CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'The sweet lassi excellent lamb chettinad garlic naan rasamalai forgettable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[1.0, 0.0, 0.0],[0.0, 0.0, 1.0],[],[],[],[],[0.5, 0.0, 0.5],[]']\n",
            " ['rasamalai'\n",
            "  'The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.'\n",
            "  'DET ADJ PROPN AUX ADJ SCONJ AUX DET NOUN NOUN CCONJ DET NOUN PROPN CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'The sweet lassi excellent lamb chettinad garlic naan rasamalai forgettable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[1.0, 0.0, 0.0],[0.0, 0.0, 1.0],[],[],[],[],[0.5, 0.0, 0.5],[]']\n",
            " ['Service' 'Service was quick.' 'PROPN AUX ADJ PUNCT' 'Service quick .'\n",
            "  '[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['bills'\n",
            "  \"Oh, don't even let me start with how expensive the bills were!\"\n",
            "  'INTJ PUNCT AUX PART ADV VERB PRON VERB ADP SCONJ ADJ DET NOUN AUX PUNCT'\n",
            "  \"Oh , n't even let start expensive bills !\"\n",
            "  '[],[],[],[0.125, 0.0, 0.875],[],[],[0.5, 0.0, 0.5],[0.0, 0.0, 1.0],[]']\n",
            " ['Service' 'Service is top notch.' 'NOUN AUX ADJ ADJ PUNCT'\n",
            "  'Service top notch .'\n",
            "  '[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[]']\n",
            " ['lambc hops' 'The best thing I tasted were the lambc hops.'\n",
            "  'DET ADJ NOUN PRON VERB AUX DET NOUN VERB PUNCT'\n",
            "  'The best thing I tasted lambc hops .'\n",
            "  '[],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['seafood' 'Even though its good seafood, the prices are too high.'\n",
            "  'ADV SCONJ PRON ADJ NOUN PUNCT DET NOUN AUX ADV ADJ PUNCT'\n",
            "  'Even though good seafood , prices high .'\n",
            "  '[0.125, 0.0, 0.875],[],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['prices' 'Even though its good seafood, the prices are too high.'\n",
            "  'ADV SCONJ PRON ADJ NOUN PUNCT DET NOUN AUX ADV ADJ PUNCT'\n",
            "  'Even though good seafood , prices high .'\n",
            "  '[0.125, 0.0, 0.875],[],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['food'\n",
            "  'In addition, the food is very good and the prices are reasonable.'\n",
            "  'ADP NOUN PUNCT DET NOUN AUX ADV ADJ CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'In addition , food good prices reasonable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[]']\n",
            " ['prices'\n",
            "  'In addition, the food is very good and the prices are reasonable.'\n",
            "  'ADP NOUN PUNCT DET NOUN AUX ADV ADJ CCONJ DET NOUN AUX ADJ PUNCT'\n",
            "  'In addition , food good prices reasonable .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[]']\n",
            " ['food' 'The food is great and authentic.'\n",
            "  'DET NOUN AUX ADJ CCONJ ADJ PUNCT' 'The food great authentic .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[]']\n",
            " ['garlic shrimp'\n",
            "  'I recommend the garlic shrimp, okra (bindi), and anything with lamb.'\n",
            "  'PRON VERB DET ADJ NOUN PUNCT PROPN PUNCT PROPN PUNCT PUNCT CCONJ PRON ADP NOUN PUNCT'\n",
            "  'I recommend garlic shrimp , okra ( bindi ) , anything lamb .'\n",
            "  '[],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['okra (bindi)'\n",
            "  'I recommend the garlic shrimp, okra (bindi), and anything with lamb.'\n",
            "  'PRON VERB DET ADJ NOUN PUNCT PROPN PUNCT PROPN PUNCT PUNCT CCONJ PRON ADP NOUN PUNCT'\n",
            "  'I recommend garlic shrimp , okra ( bindi ) , anything lamb .'\n",
            "  '[],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['lamb'\n",
            "  'I recommend the garlic shrimp, okra (bindi), and anything with lamb.'\n",
            "  'PRON VERB DET ADJ NOUN PUNCT PROPN PUNCT PROPN PUNCT PUNCT CCONJ PRON ADP NOUN PUNCT'\n",
            "  'I recommend garlic shrimp , okra ( bindi ) , anything lamb .'\n",
            "  '[],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['menu'\n",
            "  'The menu was impressive with selections ranging from a burger, to steak, to escargot.'\n",
            "  'DET NOUN AUX ADJ ADP NOUN VERB ADP DET NOUN PUNCT PART VERB PUNCT ADP NOUN PUNCT'\n",
            "  'The menu impressive selections ranging burger , steak , escargot .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[]']\n",
            " ['burger'\n",
            "  'The menu was impressive with selections ranging from a burger, to steak, to escargot.'\n",
            "  'DET NOUN AUX ADJ ADP NOUN VERB ADP DET NOUN PUNCT PART VERB PUNCT ADP NOUN PUNCT'\n",
            "  'The menu impressive selections ranging burger , steak , escargot .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[]']\n",
            " ['steak'\n",
            "  'The menu was impressive with selections ranging from a burger, to steak, to escargot.'\n",
            "  'DET NOUN AUX ADJ ADP NOUN VERB ADP DET NOUN PUNCT PART VERB PUNCT ADP NOUN PUNCT'\n",
            "  'The menu impressive selections ranging burger , steak , escargot .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[]']\n",
            " ['escargot'\n",
            "  'The menu was impressive with selections ranging from a burger, to steak, to escargot.'\n",
            "  'DET NOUN AUX ADJ ADP NOUN VERB ADP DET NOUN PUNCT PART VERB PUNCT ADP NOUN PUNCT'\n",
            "  'The menu impressive selections ranging burger , steak , escargot .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[]']\n",
            " ['breads' 'very good breads as well.' 'ADV ADJ NOUN ADV ADV PUNCT'\n",
            "  'good breads well .'\n",
            "  '[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.375, 0.0, 0.625],[]']\n",
            " ['food'\n",
            "  'Anyway, the food is good, the price is right and they have a decent wine list.'\n",
            "  'ADV PUNCT DET NOUN AUX ADJ PUNCT DET NOUN AUX ADJ CCONJ PRON VERB DET ADJ NOUN NOUN PUNCT'\n",
            "  'Anyway , food good , price right decent wine list .'\n",
            "  '[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.875, 0.0, 0.125],[],[0.0, 0.0, 1.0],[]']\n",
            " ['price'\n",
            "  'Anyway, the food is good, the price is right and they have a decent wine list.'\n",
            "  'ADV PUNCT DET NOUN AUX ADJ PUNCT DET NOUN AUX ADJ CCONJ PRON VERB DET ADJ NOUN NOUN PUNCT'\n",
            "  'Anyway , food good , price right decent wine list .'\n",
            "  '[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.875, 0.0, 0.125],[],[0.0, 0.0, 1.0],[]']\n",
            " ['wine list'\n",
            "  'Anyway, the food is good, the price is right and they have a decent wine list.'\n",
            "  'ADV PUNCT DET NOUN AUX ADJ PUNCT DET NOUN AUX ADJ CCONJ PRON VERB DET ADJ NOUN NOUN PUNCT'\n",
            "  'Anyway , food good , price right decent wine list .'\n",
            "  '[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.875, 0.0, 0.125],[],[0.0, 0.0, 1.0],[]']\n",
            " ['food'\n",
            "  'The food was lousy -too sweet or too salty and the portions tiny.'\n",
            "  'DET NOUN AUX ADJ PUNCT ADJ CCONJ ADV ADJ CCONJ DET NOUN ADJ PUNCT'\n",
            "  'The food lousy -too sweet salty portions tiny .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.75, 0.25],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['portions'\n",
            "  'The food was lousy -too sweet or too salty and the portions tiny.'\n",
            "  'DET NOUN AUX ADJ PUNCT ADJ CCONJ ADV ADJ CCONJ DET NOUN ADJ PUNCT'\n",
            "  'The food lousy -too sweet salty portions tiny .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.75, 0.25],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['coconut rice' 'But the coconut rice was good.'\n",
            "  'CCONJ DET ADJ NOUN AUX ADJ PUNCT' 'But coconut rice good .'\n",
            "  '[],[],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[]']\n",
            " ['Tom Kha soup' 'And the Tom Kha soup was pathetic.'\n",
            "  'CCONJ DET PROPN PROPN NOUN AUX ADJ PUNCT'\n",
            "  'And Tom Kha soup pathetic .'\n",
            "  '[],[0.125, 0.0, 0.875],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['food' 'The food now is inconsistent.' 'DET NOUN ADV AUX ADJ PUNCT'\n",
            "  'The food inconsistent .' '[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['crunchy tuna' 'Try the crunchy tuna, it is to die for.'\n",
            "  'VERB DET ADJ NOUN PUNCT PRON AUX PART VERB ADP PUNCT'\n",
            "  'Try crunchy tuna , .' '[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['prices' 'Reasonable prices.' 'ADJ NOUN PUNCT' 'Reasonable prices .'\n",
            "  '[0.5, 0.0, 0.5],[0.0, 0.0, 1.0],[]']\n",
            " ['service'\n",
            "  'Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.'\n",
            "  'VERB ADP DET ADJ NOUN CCONJ ADJ NOUN ADP DET ADJ NOUN CCONJ PRON VERB PRON DET NOUN ADP DET ADJ NOUN PUNCT'\n",
            "  'Add great service great food reasonable price beginning great evening .'\n",
            "  '[0.625, 0.125, 0.25],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['food'\n",
            "  'Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.'\n",
            "  'VERB ADP DET ADJ NOUN CCONJ ADJ NOUN ADP DET ADJ NOUN CCONJ PRON VERB PRON DET NOUN ADP DET ADJ NOUN PUNCT'\n",
            "  'Add great service great food reasonable price beginning great evening .'\n",
            "  '[0.625, 0.125, 0.25],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['price'\n",
            "  'Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.'\n",
            "  'VERB ADP DET ADJ NOUN CCONJ ADJ NOUN ADP DET ADJ NOUN CCONJ PRON VERB PRON DET NOUN ADP DET ADJ NOUN PUNCT'\n",
            "  'Add great service great food reasonable price beginning great evening .'\n",
            "  '[0.625, 0.125, 0.25],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['food'\n",
            "  'Unfortunately, the food was NOT something to get worked up about.'\n",
            "  'ADV PUNCT DET NOUN AUX PART PRON PART AUX VERB ADP ADP PUNCT'\n",
            "  'Unfortunately , food NOT something get worked .'\n",
            "  '[0.0, 0.875, 0.125],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['food' 'The food is great and reasonably priced.'\n",
            "  'DET NOUN AUX ADJ CCONJ ADV VERB PUNCT'\n",
            "  'The food great reasonably priced .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.25, 0.625],[],[]']\n",
            " ['priced' 'The food is great and reasonably priced.'\n",
            "  'DET NOUN AUX ADJ CCONJ ADV VERB PUNCT'\n",
            "  'The food great reasonably priced .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.25, 0.625],[],[]']\n",
            " ['calzones' 'Their calzones are horrific, bad, vomit-inducing, YUCK.'\n",
            "  'PRON NOUN AUX ADJ PUNCT ADJ PUNCT NOUN PUNCT VERB PUNCT PROPN PUNCT'\n",
            "  'Their calzones horrific , bad , vomit-inducing , YUCK .'\n",
            "  '[],[],[],[],[0.0, 0.625, 0.375],[],[],[],[],[]']\n",
            " ['turnip cake'\n",
            "  'A few tips: skip the turnip cake, roast pork buns and egg custards.'\n",
            "  'DET ADJ NOUN PUNCT VERB DET NOUN NOUN PUNCT NOUN NOUN NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'A tips : skip turnip cake , roast pork buns egg custards .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['roast pork buns'\n",
            "  'A few tips: skip the turnip cake, roast pork buns and egg custards.'\n",
            "  'DET ADJ NOUN PUNCT VERB DET NOUN NOUN PUNCT NOUN NOUN NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'A tips : skip turnip cake , roast pork buns egg custards .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['egg custards'\n",
            "  'A few tips: skip the turnip cake, roast pork buns and egg custards.'\n",
            "  'DET ADJ NOUN PUNCT VERB DET NOUN NOUN PUNCT NOUN NOUN NOUN CCONJ NOUN NOUN PUNCT'\n",
            "  'A tips : skip turnip cake , roast pork buns egg custards .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['bagels' 'The bagels are fabulous.' 'DET NOUN AUX ADJ PUNCT'\n",
            "  'The bagels fabulous .' '[],[0.0, 0.0, 1.0],[0.875, 0.125, 0.0],[]']\n",
            " ['ambiance'\n",
            "  'While the ambiance and atmosphere were great, the food and service could have been a lot better.'\n",
            "  'SCONJ DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN CCONJ NOUN AUX AUX AUX DET NOUN ADV PUNCT'\n",
            "  'While ambiance atmosphere great , food service could lot better .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.875, 0.0, 0.125],[]']\n",
            " ['atmosphere'\n",
            "  'While the ambiance and atmosphere were great, the food and service could have been a lot better.'\n",
            "  'SCONJ DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN CCONJ NOUN AUX AUX AUX DET NOUN ADV PUNCT'\n",
            "  'While ambiance atmosphere great , food service could lot better .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.875, 0.0, 0.125],[]']\n",
            " ['food'\n",
            "  'While the ambiance and atmosphere were great, the food and service could have been a lot better.'\n",
            "  'SCONJ DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN CCONJ NOUN AUX AUX AUX DET NOUN ADV PUNCT'\n",
            "  'While ambiance atmosphere great , food service could lot better .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.875, 0.0, 0.125],[]']\n",
            " ['service'\n",
            "  'While the ambiance and atmosphere were great, the food and service could have been a lot better.'\n",
            "  'SCONJ DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN CCONJ NOUN AUX AUX AUX DET NOUN ADV PUNCT'\n",
            "  'While ambiance atmosphere great , food service could lot better .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.875, 0.0, 0.125],[]']\n",
            " ['waitress' 'Our waitress was sweet and accomodating, not overbearing.'\n",
            "  'PRON NOUN AUX ADJ CCONJ ADJ PUNCT PART ADJ PUNCT'\n",
            "  'Our waitress sweet accomodating , overbearing .'\n",
            "  '[],[],[0.0, 0.0, 1.0],[],[],[],[]']\n",
            " ['fish'\n",
            "  'My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.'\n",
            "  'PRON NOUN PUNCT PRON ADP DET NOUN ADP DET NOUN ADP DET NOUN AUX ADV ADJ PUNCT'\n",
            "  'My goodness , everything fish rice seaweed absolutely amazing .'\n",
            "  '[],[0.625, 0.0, 0.375],[],[],[],[0.0, 0.0, 1.0],[],[0.5, 0.0, 0.5],[0.5, 0.25, 0.25],[]']\n",
            " ['rice'\n",
            "  'My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.'\n",
            "  'PRON NOUN PUNCT PRON ADP DET NOUN ADP DET NOUN ADP DET NOUN AUX ADV ADJ PUNCT'\n",
            "  'My goodness , everything fish rice seaweed absolutely amazing .'\n",
            "  '[],[0.625, 0.0, 0.375],[],[],[],[0.0, 0.0, 1.0],[],[0.5, 0.0, 0.5],[0.5, 0.25, 0.25],[]']\n",
            " ['seaweed'\n",
            "  'My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.'\n",
            "  'PRON NOUN PUNCT PRON ADP DET NOUN ADP DET NOUN ADP DET NOUN AUX ADV ADJ PUNCT'\n",
            "  'My goodness , everything fish rice seaweed absolutely amazing .'\n",
            "  '[],[0.625, 0.0, 0.375],[],[],[],[0.0, 0.0, 1.0],[],[0.5, 0.0, 0.5],[0.5, 0.25, 0.25],[]']\n",
            " ['spreads'\n",
            "  'Good spreads, great beverage selections and bagels really tasty.'\n",
            "  'ADJ NOUN PUNCT ADJ NOUN NOUN CCONJ NOUN ADV ADJ PUNCT'\n",
            "  'Good spreads , great beverage selections bagels really tasty .'\n",
            "  '[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.625, 0.25, 0.125],[]']\n",
            " ['beverage selections'\n",
            "  'Good spreads, great beverage selections and bagels really tasty.'\n",
            "  'ADJ NOUN PUNCT ADJ NOUN NOUN CCONJ NOUN ADV ADJ PUNCT'\n",
            "  'Good spreads , great beverage selections bagels really tasty .'\n",
            "  '[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.625, 0.25, 0.125],[]']\n",
            " ['bagels'\n",
            "  'Good spreads, great beverage selections and bagels really tasty.'\n",
            "  'ADJ NOUN PUNCT ADJ NOUN NOUN CCONJ NOUN ADV ADJ PUNCT'\n",
            "  'Good spreads , great beverage selections bagels really tasty .'\n",
            "  '[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.625, 0.25, 0.125],[]']\n",
            " ['food options' 'The food options rule.' 'DET NOUN NOUN NOUN PUNCT'\n",
            "  'The food options rule .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.25, 0.75],[0.25, 0.0, 0.75],[]']\n",
            " ['Japanese Tapas' 'Consistently good Japanese Tapas.'\n",
            "  'ADV ADJ ADJ PROPN PUNCT' 'Consistently good Japanese Tapas .'\n",
            "  '[0.25, 0.0, 0.75],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['sushi' 'The sushi was awful!' 'DET NOUN AUX ADJ PUNCT'\n",
            "  'The sushi awful !' '[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['food' 'The food was great.' 'DET NOUN AUX ADJ PUNCT'\n",
            "  'The food great .' '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['meal'\n",
            "  'With the theater 2 blocks away we had a delicious meal in a beautiful room.'\n",
            "  'ADP DET NOUN NUM NOUN ADV PRON VERB DET ADJ NOUN ADP DET ADJ NOUN PUNCT'\n",
            "  'With theater 2 blocks away delicious meal beautiful room .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[]']\n",
            " ['room'\n",
            "  'With the theater 2 blocks away we had a delicious meal in a beautiful room.'\n",
            "  'ADP DET NOUN NUM NOUN ADV PRON VERB DET ADJ NOUN ADP DET ADJ NOUN PUNCT'\n",
            "  'With theater 2 blocks away delicious meal beautiful room .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.0, 0.0, 1.0],[]']\n",
            " ['pizza'\n",
            "  'I love the fact that the pizza tastes so good and is so cheap.'\n",
            "  'PRON VERB DET NOUN SCONJ DET NOUN VERB ADV ADJ CCONJ AUX ADV ADJ PUNCT'\n",
            "  'I love fact pizza tastes good cheap .'\n",
            "  '[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[]']\n",
            " ['Service' 'Service was prompt, friendly and great.'\n",
            "  'PROPN AUX ADJ PUNCT ADJ CCONJ ADJ PUNCT'\n",
            "  'Service prompt , friendly great .'\n",
            "  '[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['lamb chop'\n",
            "  \"I haven't eat a lamb chop as delicious as that, the salads are really nice dressed with lemon and extra virgnin olive oil.\"\n",
            "  'PRON AUX PART VERB DET NOUN NOUN ADV ADJ ADP PRON PUNCT DET NOUN AUX ADV ADV ADJ ADP NOUN CCONJ ADJ ADJ NOUN NOUN PUNCT'\n",
            "  \"I n't eat lamb chop delicious , salads really nice dressed lemon extra virgnin olive oil .\"\n",
            "  '[],[],[],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.875, 0.0, 0.125],[],[],[0.0, 0.5, 0.5],[],[0.0, 0.125, 0.875],[0.0, 0.125, 0.875],[]']\n",
            " ['salads'\n",
            "  \"I haven't eat a lamb chop as delicious as that, the salads are really nice dressed with lemon and extra virgnin olive oil.\"\n",
            "  'PRON AUX PART VERB DET NOUN NOUN ADV ADJ ADP PRON PUNCT DET NOUN AUX ADV ADV ADJ ADP NOUN CCONJ ADJ ADJ NOUN NOUN PUNCT'\n",
            "  \"I n't eat lamb chop delicious , salads really nice dressed lemon extra virgnin olive oil .\"\n",
            "  '[],[],[],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.875, 0.0, 0.125],[],[],[0.0, 0.5, 0.5],[],[0.0, 0.125, 0.875],[0.0, 0.125, 0.875],[]']\n",
            " ['service' \"Drawbacks: service is slow and they don't toast!\"\n",
            "  'NOUN PUNCT NOUN AUX ADJ CCONJ PRON AUX PART VERB PUNCT'\n",
            "  \"Drawbacks : service slow n't toast !\"\n",
            "  '[0.375, 0.125, 0.5],[],[0.0, 0.0, 1.0],[],[],[],[]']\n",
            " ['prices' 'The prices were fantastic.' 'DET NOUN AUX ADJ PUNCT'\n",
            "  'The prices fantastic .' '[],[0.0, 0.0, 1.0],[0.375, 0.0, 0.625],[]']\n",
            " ['food'\n",
            "  'The food is terrible and overall, I would have to say avoid at all costs.'\n",
            "  'DET NOUN AUX ADJ CCONJ ADJ PUNCT PRON AUX VERB PART VERB VERB ADP DET NOUN PUNCT'\n",
            "  'The food terrible overall , I would say avoid costs .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.625, 0.375],[0.0, 0.0, 1.0],[],[],[],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['food' 'The food is prepared quickly and efficiently.'\n",
            "  'DET NOUN AUX VERB ADV CCONJ ADV PUNCT'\n",
            "  'The food prepared quickly efficiently .'\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[]']\n",
            " ['food' 'The food is fresh, delicious, and reasonably priced.'\n",
            "  'DET NOUN AUX ADJ PUNCT ADJ PUNCT CCONJ ADV VERB PUNCT'\n",
            "  'The food fresh , delicious , reasonably priced .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.375, 0.625, 0.0],[],[0.75, 0.0, 0.25],[],[0.125, 0.25, 0.625],[],[]']\n",
            " ['priced' 'The food is fresh, delicious, and reasonably priced.'\n",
            "  'DET NOUN AUX ADJ PUNCT ADJ PUNCT CCONJ ADV VERB PUNCT'\n",
            "  'The food fresh , delicious , reasonably priced .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.375, 0.625, 0.0],[],[0.75, 0.0, 0.25],[],[0.125, 0.25, 0.625],[],[]']\n",
            " ['waiter'\n",
            "  \"As we were leaving, the couple standing by the door said to another waiter, we're not in a hurry.\"\n",
            "  'SCONJ PRON AUX VERB PUNCT DET NOUN VERB ADP DET NOUN VERB ADP DET NOUN PUNCT PRON AUX PART ADP DET NOUN PUNCT'\n",
            "  \"As leaving , couple standing said another waiter , 're hurry .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.0, 0.125, 0.875],[0.125, 0.0, 0.875],[],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['outdoor atmosphere'\n",
            "  'The outdoor atmosphere of sitting on the sidewalk watching the world go by 50 feet away on 6th avenue on a cool evening was wonderful.'\n",
            "  'DET ADJ NOUN ADP VERB ADP DET NOUN VERB DET NOUN VERB ADP NUM NOUN ADV ADP ADJ NOUN ADP DET ADJ NOUN AUX ADJ PUNCT'\n",
            "  'The outdoor atmosphere sitting sidewalk watching world go 50 feet away 6th avenue cool evening wonderful .'\n",
            "  '[],[],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[],[0.25, 0.375, 0.375],[],[0.75, 0.0, 0.25],[]']\n",
            " ['toppings' 'A large is $20, and toppings are about $3 each.'\n",
            "  'DET ADJ AUX SYM NUM PUNCT CCONJ NOUN AUX ADV SYM NUM PRON PUNCT'\n",
            "  'A large $ 20 , toppings $ 3 .'\n",
            "  '[],[0.25, 0.125, 0.625],[],[],[],[0.0, 0.0, 1.0],[],[],[]']\n",
            " ['spicy tuna' \"The spicy tuna and salmon are the best we've ever had.\"\n",
            "  'DET NOUN NOUN CCONJ NOUN AUX DET ADJ PRON AUX ADV VERB PUNCT'\n",
            "  \"The spicy tuna salmon best 've ever .\"\n",
            "  '[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[]']\n",
            " ['salmon' \"The spicy tuna and salmon are the best we've ever had.\"\n",
            "  'DET NOUN NOUN CCONJ NOUN AUX DET ADJ PRON AUX ADV VERB PUNCT'\n",
            "  \"The spicy tuna salmon best 've ever .\"\n",
            "  '[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[]']\n",
            " ['food'\n",
            "  'The food was very good, a great deal, and the place its self was great.'\n",
            "  'DET NOUN AUX ADV ADJ PUNCT DET ADJ NOUN PUNCT CCONJ DET NOUN PRON NOUN AUX ADJ PUNCT'\n",
            "  'The food good , great deal , place self great .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['place'\n",
            "  'The food was very good, a great deal, and the place its self was great.'\n",
            "  'DET NOUN AUX ADV ADJ PUNCT DET ADJ NOUN PUNCT CCONJ DET NOUN PRON NOUN AUX ADJ PUNCT'\n",
            "  'The food good , great deal , place self great .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['food'\n",
            "  \"The food is usually good but it certainly isn't a relaxing place to go.\"\n",
            "  'DET NOUN AUX ADV ADJ CCONJ PRON ADV AUX PART DET ADJ NOUN PART VERB PUNCT'\n",
            "  \"The food usually good certainly n't relaxing place go .\"\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.25, 0.0, 0.75],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['place'\n",
            "  \"The food is usually good but it certainly isn't a relaxing place to go.\"\n",
            "  'DET NOUN AUX ADV ADJ CCONJ PRON ADV AUX PART DET ADJ NOUN PART VERB PUNCT'\n",
            "  \"The food usually good certainly n't relaxing place go .\"\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[0.25, 0.0, 0.75],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['dinner'\n",
            "  \"After dinner, take your date to the HUGE dance floor, probably one of the biggest you'll see in NY.\"\n",
            "  'ADP NOUN PUNCT VERB PRON NOUN ADP DET ADJ NOUN NOUN PUNCT ADV NUM ADP DET ADJ PRON AUX VERB ADP PROPN PUNCT'\n",
            "  \"After dinner , date HUGE dance floor , probably biggest 'll see NY .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.125, 0.0, 0.875],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['dance floor'\n",
            "  \"After dinner, take your date to the HUGE dance floor, probably one of the biggest you'll see in NY.\"\n",
            "  'ADP NOUN PUNCT VERB PRON NOUN ADP DET ADJ NOUN NOUN PUNCT ADV NUM ADP DET ADJ PRON AUX VERB ADP PROPN PUNCT'\n",
            "  \"After dinner , date HUGE dance floor , probably biggest 'll see NY .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.125, 0.0, 0.875],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[]']\n",
            " ['server'\n",
            "  'The server was really cool and served us our food and drinks with a smile.'\n",
            "  'DET NOUN AUX ADV ADJ CCONJ VERB PRON PRON NOUN CCONJ NOUN ADP DET NOUN PUNCT'\n",
            "  'The server really cool served us food drinks smile .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[]']\n",
            " ['served'\n",
            "  'The server was really cool and served us our food and drinks with a smile.'\n",
            "  'DET NOUN AUX ADV ADJ CCONJ VERB PRON PRON NOUN CCONJ NOUN ADP DET NOUN PUNCT'\n",
            "  'The server really cool served us food drinks smile .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[]']\n",
            " ['food'\n",
            "  'The server was really cool and served us our food and drinks with a smile.'\n",
            "  'DET NOUN AUX ADV ADJ CCONJ VERB PRON PRON NOUN CCONJ NOUN ADP DET NOUN PUNCT'\n",
            "  'The server really cool served us food drinks smile .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[]']\n",
            " ['drinks'\n",
            "  'The server was really cool and served us our food and drinks with a smile.'\n",
            "  'DET NOUN AUX ADV ADJ CCONJ VERB PRON PRON NOUN CCONJ NOUN ADP DET NOUN PUNCT'\n",
            "  'The server really cool served us food drinks smile .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.625, 0.0, 0.375],[0.25, 0.125, 0.625],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[]']\n",
            " ['dishes'\n",
            "  \"The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\"\n",
            "  'DET NOUN VERB AUX ADJ PUNCT ADV ADJ CCONJ ADJ ADP DET NOUN NOUN PUNCT NOUN ADP NOUN PUNCT ADJ ADJ NOUN ADP DET ADJ PROPN NOUN NOUN PUNCT DET ADJ CCONJ NOUN PRON AUX ADV VERB PUNCT PUNCT'\n",
            "  \"The dishes offered unique , tasty fresh lamb sausages , sardines biscuits , large whole shrimp amazing pistachio ice cream ( best freshest I 've ever ) .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.375, 0.0, 0.625],[],[0.625, 0.25, 0.125],[0.375, 0.625, 0.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.25, 0.125, 0.625],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.75, 0.0, 0.25],[],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['lamb sausages'\n",
            "  \"The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\"\n",
            "  'DET NOUN VERB AUX ADJ PUNCT ADV ADJ CCONJ ADJ ADP DET NOUN NOUN PUNCT NOUN ADP NOUN PUNCT ADJ ADJ NOUN ADP DET ADJ PROPN NOUN NOUN PUNCT DET ADJ CCONJ NOUN PRON AUX ADV VERB PUNCT PUNCT'\n",
            "  \"The dishes offered unique , tasty fresh lamb sausages , sardines biscuits , large whole shrimp amazing pistachio ice cream ( best freshest I 've ever ) .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.375, 0.0, 0.625],[],[0.625, 0.25, 0.125],[0.375, 0.625, 0.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.25, 0.125, 0.625],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.75, 0.0, 0.25],[],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['sardines with biscuits'\n",
            "  \"The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\"\n",
            "  'DET NOUN VERB AUX ADJ PUNCT ADV ADJ CCONJ ADJ ADP DET NOUN NOUN PUNCT NOUN ADP NOUN PUNCT ADJ ADJ NOUN ADP DET ADJ PROPN NOUN NOUN PUNCT DET ADJ CCONJ NOUN PRON AUX ADV VERB PUNCT PUNCT'\n",
            "  \"The dishes offered unique , tasty fresh lamb sausages , sardines biscuits , large whole shrimp amazing pistachio ice cream ( best freshest I 've ever ) .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.375, 0.0, 0.625],[],[0.625, 0.25, 0.125],[0.375, 0.625, 0.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.25, 0.125, 0.625],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.75, 0.0, 0.25],[],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['large whole shrimp'\n",
            "  \"The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\"\n",
            "  'DET NOUN VERB AUX ADJ PUNCT ADV ADJ CCONJ ADJ ADP DET NOUN NOUN PUNCT NOUN ADP NOUN PUNCT ADJ ADJ NOUN ADP DET ADJ PROPN NOUN NOUN PUNCT DET ADJ CCONJ NOUN PRON AUX ADV VERB PUNCT PUNCT'\n",
            "  \"The dishes offered unique , tasty fresh lamb sausages , sardines biscuits , large whole shrimp amazing pistachio ice cream ( best freshest I 've ever ) .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.375, 0.0, 0.625],[],[0.625, 0.25, 0.125],[0.375, 0.625, 0.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.25, 0.125, 0.625],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.75, 0.0, 0.25],[],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['pistachio ice cream'\n",
            "  \"The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\"\n",
            "  'DET NOUN VERB AUX ADJ PUNCT ADV ADJ CCONJ ADJ ADP DET NOUN NOUN PUNCT NOUN ADP NOUN PUNCT ADJ ADJ NOUN ADP DET ADJ PROPN NOUN NOUN PUNCT DET ADJ CCONJ NOUN PRON AUX ADV VERB PUNCT PUNCT'\n",
            "  \"The dishes offered unique , tasty fresh lamb sausages , sardines biscuits , large whole shrimp amazing pistachio ice cream ( best freshest I 've ever ) .\"\n",
            "  '[],[0.0, 0.0, 1.0],[],[0.375, 0.0, 0.625],[],[0.625, 0.25, 0.125],[0.375, 0.625, 0.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.25, 0.125, 0.625],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[0.25, 0.0, 0.75],[],[0.75, 0.0, 0.25],[],[],[],[0.0, 0.0, 1.0],[],[]']\n",
            " ['office lunch' 'Went there for an office lunch.'\n",
            "  'VERB ADV ADP DET NOUN NOUN PUNCT' 'Went office lunch .'\n",
            "  '[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[]']\n",
            " ['dinner'\n",
            "  \"We've only eaten in the restaurant once, but we have ordered many times for dinner.\"\n",
            "  'PRON AUX ADV VERB ADP DET NOUN ADV PUNCT CCONJ PRON AUX VERB ADJ NOUN ADP NOUN PUNCT'\n",
            "  \"We 've eaten restaurant , ordered many times dinner .\"\n",
            "  '[],[],[],[0.0, 0.0, 1.0],[],[],[0.0, 0.0, 1.0],[0.5, 0.0, 0.5],[],[]']]\n"
          ]
        }
      ],
      "source": [
        "# TEST DATASET\n",
        "df_test = DF_test\n",
        "\n",
        "list_test = []\n",
        "label_test = []\n",
        "\n",
        "for i in range(len(df_test)):\n",
        "    pos_tag = [X.pos_ for X in  df_test.token_text[i]]\n",
        "    pos_tag_text = \" \".join(pos_tag)\n",
        "    senti_word = \" \".join(df_test.Sentiword[i])\n",
        "    score_by_word = \",\".join(str(v) for v in df_test.Score_by_word[i])\n",
        "    \n",
        "    list_test.append(\n",
        "        (df_test.term[i],\n",
        "        df_test.text[i],\n",
        "        pos_tag_text,\n",
        "        senti_word,\n",
        "        score_by_word,\n",
        "        ))\n",
        "    label_test.append(df_test.polarity[i])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "Restaurant_Test = np.array(list_test)\n",
        "print(Restaurant_Test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPTaxywRkIKh"
      },
      "source": [
        "## Vectorisation — TF/IDF\n",
        "\n",
        "* Aux fins de la plupart des modélisations mathématiques effectuées sur le texte et aux fins de cette expérimentation, différents processus de « vectorisation » ont été mis en oeuvre.\n",
        "\n",
        "* Le contenu textuel seul ne peut pas être modifié et contraint dans l'espace mathématique sans être transformé en nombres dans le but d'être lu par un algorithme d'apprentissage automatique.\n",
        "\n",
        "* C'est pourquoi pour les besoins des méthodes supervisées dans ce projet, différents types de vectorisation ont été utilisés pour convertir des données qualitatives en données quantitatives afin de les manipuler mathématiquement. Ces vecteurs deviennent des caractéristiques intégrées pour les modèles.\n",
        "\n",
        "### Fréquence de terme/Fréquence de document inverse (TF/IDF)\n",
        "Il s'agit de la technique de vectorisation utilisée pour le modèle Support Vector Machine.\n",
        "\n",
        "* TF/IDF a été déployé sur les données d'entraînement avec une approche unigramme qui compte chaque mot individuel comme un terme. La « fréquence des termes » correspond à la fréquence à laquelle un certain mot apparaît dans le texte, la « fréquence inverse du document » fait référence à la réduction de la signification des mots qui apparaissent le plus souvent dans tout le texte.\n",
        "* Cela sert à faire des mots que l'on voit fréquemment dans un document donné mais pas nécessairement dans tous les documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzwVmzfKkhvO"
      },
      "source": [
        "### Premier test avec seulement la colonne text comme variable explicative\n",
        "Ce premier test ne signifie pas grand chose, mais il permet de montrer l'efficacité de SVM. Il doit prédire sans savoir le term à analyser, et donc sans savoir pourquoi la même phrase peut avoir une polarité positive et parfois négative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULqhA4m8kEq3",
        "outputId": "24fec0d5-b14d-4e1b-8c8e-707b7dd8cba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.031386s; Prediction time: 0.019516s\n",
            "positive:  {'precision': 0.868421052631579, 'recall': 0.9705882352941176, 'f1-score': 0.9166666666666667, 'support': 68}\n",
            "negative:  {'precision': 0.875, 'recall': 0.7777777777777778, 'f1-score': 0.823529411764706, 'support': 18}\n",
            "neutral:  {'precision': 0.75, 'recall': 0.3, 'f1-score': 0.4285714285714285, 'support': 10}\n"
          ]
        }
      ],
      "source": [
        "# Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "\n",
        "train_vectors = vectorizer.fit_transform(DF_train['text'])\n",
        "test_vectors = vectorizer.transform(DF_test['text'])\n",
        "\n",
        "# Perform classification with SVM, kernel=linear\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, DF_train['polarity'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "\n",
        "# Resultats\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "\n",
        "report = classification_report(DF_test['polarity'], prediction_linear, output_dict=True)\n",
        "\n",
        "\n",
        "print('positive: ', report['positive'])\n",
        "print('negative: ', report['negative'])\n",
        "print('neutral: ', report['neutral'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McDFQK7lLHo"
      },
      "source": [
        "Là, notre modèle prédit positif ou négatif sans savoir le term dont il s'agit. Il n'a que les phrases pour prédire. Donc ce n'est pas ce que nosu cherchons à observer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIO2zNN6lY40"
      },
      "source": [
        "### Normalisation des dimensions de nos listes.\n",
        "Afin d'avoir le même nombres de features dans chaque liste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkMyWG73lP-F",
        "outputId": "a630ee6c-1d1e-4261-b649-1620b7e8879e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['appetizers All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!! DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT All appetizers salads fabulous , steak mouth watering pasta delicious ! ! ! [],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]',\n",
              " 'salads All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!! DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT All appetizers salads fabulous , steak mouth watering pasta delicious ! ! ! [],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]',\n",
              " 'steak All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!! DET DET NOUN CCONJ NOUN AUX ADJ PUNCT DET NOUN AUX NOUN NOUN CCONJ DET NOUN AUX ADJ PUNCT PUNCT PUNCT All appetizers salads fabulous , steak mouth watering pasta delicious ! ! ! [],[0.0, 0.0, 1.0],[],[0.875, 0.125, 0.0],[],[],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[0.75, 0.0, 0.25],[],[],[]']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### TEST ###\n",
        "L = len(Restaurant_Test)\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(0,L):\n",
        "    X_test.append(Restaurant_Test[i][0] + \" \" + Restaurant_Test[i][1] + \" \" + Restaurant_Test[i][2] + \" \" + Restaurant_Test[i][3]+ \" \" + Restaurant_Test[i][4])\n",
        "    y_test.append(label_test[i])\n",
        "\n",
        "X_test[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HneuWf3flxpE",
        "outputId": "290deee9-c2fc-4ffc-bb01-0340e48595bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['staff But the staff was so horrible to us. CCONJ DET NOUN AUX ADV ADJ ADP PRON PUNCT But staff horrible us . [],[0.0, 0.0, 1.0],[0.0, 0.625, 0.375],[],[]',\n",
              " \"food To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora. PART AUX ADV ADJ PUNCT DET ADJ VERB NOUN AUX DET NOUN PUNCT PRON AUX ADP ADJ PUNCT CCONJ AUX PART VERB ADP ADP DET DET ADJ NOUN ADP PROPN PUNCT To completely fair , redeeming factor food , average , could n't make deficiencies Teodora . [],[0.5, 0.0, 0.5],[0.625, 0.0, 0.375],[],[],[0.0, 0.0, 1.0],[0.0, 0.0, 1.0],[],[0.0, 0.0, 1.0],[],[],[],[],[0.125, 0.125, 0.75],[],[]\",\n",
              " \"food The food is uniformly exceptional, with a very capable kitchen which will proudly whip up whatever you feel like eating, whether it's on the menu or not. DET NOUN AUX ADV ADJ PUNCT ADP DET ADV ADJ NOUN PRON AUX ADV VERB ADP PRON PRON VERB ADP VERB PUNCT SCONJ PRON AUX ADP DET NOUN CCONJ PART PUNCT The food uniformly exceptional , capable kitchen proudly whip whatever feel like eating , whether 's menu . [],[0.0, 0.0, 1.0],[],[],[],[0.125, 0.0, 0.875],[0.0, 0.0, 1.0],[0.125, 0.0, 0.875],[],[],[],[],[0.0, 0.0, 1.0],[],[],[],[0.0, 0.0, 1.0],[]\"]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### TRAIN ###\n",
        "\n",
        "L = len(Restaurant_Train)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(0,L):\n",
        "    X_train.append(Restaurant_Train[i][0] + \" \" + Restaurant_Train[i][1] + \" \" + Restaurant_Train[i][2] + \" \" + Restaurant_Train[i][3]+ \" \" + Restaurant_Train[i][4])\n",
        "    y_train.append(label_train[i])\n",
        "\n",
        "X_train[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBRXCbtLl2He"
      },
      "source": [
        "### Vectorisation avec TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMSqF9xMl3Ls",
        "outputId": "65e4a600-194f-475e-9842-a28792c965b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3602, 3741)\n",
            "(3602, 3741)\n",
            "(96, 3741)\n",
            "(96, 3741)\n"
          ]
        }
      ],
      "source": [
        "# Creation des vecteurs\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "X_test_tf = tf_transformer.transform(X_test_counts)\n",
        "\n",
        "print(X_train_counts.shape)\n",
        "print(X_train_tf.shape)\n",
        "\n",
        "print(X_test_counts.shape)\n",
        "print(X_test_tf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-g2GTxWmNcq",
        "outputId": "9a4f347c-7dc1-4dc6-fa7a-9b112eb65d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.925153s; Prediction time: 0.043537s\n",
            "positive:  {'precision': 0.881578947368421, 'recall': 0.9852941176470589, 'f1-score': 0.9305555555555556, 'support': 68}\n",
            "negative:  {'precision': 0.9230769230769231, 'recall': 0.6666666666666666, 'f1-score': 0.7741935483870968, 'support': 18}\n",
            "neutral:  {'precision': 0.8571428571428571, 'recall': 0.6, 'f1-score': 0.7058823529411764, 'support': 10}\n"
          ]
        }
      ],
      "source": [
        "# Test avec kernel=rbf\n",
        "classifier_linear = svm.SVC(kernel='rbf')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(X_train_tf, y_train)\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(X_test_tf)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "\n",
        "# Resultats\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "\n",
        "report = classification_report(y_test, prediction_linear, output_dict=True)\n",
        "\n",
        "print('positive: ', report['positive'])\n",
        "print('negative: ', report['negative'])\n",
        "print('neutral: ', report['neutral'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0U2R07SmX_r"
      },
      "source": [
        "Les résultats sont déjà très bon, avec une précision de 0.88 pour les positif, 1.0 pour les negatif et 0.875 pour les neutre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWKNsXTUmho9",
        "outputId": "720b111f-2308-4c85-f849-f3a535bd828a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 2.122323s; Prediction time: 0.043537s\n",
            "positive:  {'precision': 0.8933333333333333, 'recall': 0.9852941176470589, 'f1-score': 0.9370629370629371, 'support': 68}\n",
            "negative:  {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 18}\n",
            "neutral:  {'precision': 0.8888888888888888, 'recall': 0.8, 'f1-score': 0.8421052631578948, 'support': 10}\n"
          ]
        }
      ],
      "source": [
        "# Test avec kernel=poly\n",
        "classifier_linear = svm.SVC(kernel='poly')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(X_train_tf, y_train)\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(X_test_tf)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "\n",
        "# Resultats\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "\n",
        "report = classification_report(y_test, prediction_linear, output_dict=True)\n",
        "\n",
        "print('positive: ', report['positive'])\n",
        "print('negative: ', report['negative'])\n",
        "print('neutral: ', report['neutral'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtdrcPV-mp2Q"
      },
      "source": [
        "- F1 Score positif --> 0.937 --> 93.7 % (supérieur à rbf 0.931 --> 93.1 % )\n",
        "- F1 Score negatif --> 0.8 --> 8 % (supérieur à rbf 0.77 --> 77 %)\n",
        "- F1 Score neutre --> 0.84 --> 84 % (supérieur à rbf 0.70 --> 70 %)\n",
        "\n",
        "D'après les résultats obtenu, le noyau Polynomial semble donner de meilleurs résultats que le kernel Radial basis function (rbf) ou linéaire, notamment pour les positifs et les neutres. On garde alors la typologie avec le kernel POLY."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TLN_projet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
